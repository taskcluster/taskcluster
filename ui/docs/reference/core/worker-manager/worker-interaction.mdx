---
title: Worker-Manager - Worker Interaction
order: 100
---
import Warning from 'taskcluster-ui/views/Documentation/components/Warning';

# Worker-Manager - Worker Interaction

This document outlines how workers interact with the worker-manager service.

## Worker Startup

### Initial Information

Workers must "know" the following at startup:

 * [Taskcluster root URL](/docs/manual/using/root-urls)
 * `providerId`
 * `workerPoolId`
 * `workerGroup` and `workerId`

In cloud systems, this is typically communicated as "user data" through the cloud provider's metadata service.
Other deployments may provide this information statically, such as via Puppet. Workers are also provided
`workerConfig` by each provider that they can use to configure themselves on top of this required data.

| Cloud Provider | `workerConfig` Location                                                               |
| -------------- | ------------------------------------------------------------------------------------- |
| Google         | `http://metadata.google.internal/computeMetadata/v1/instance/attributes/taskcluster`  |
| Amazon         | `http://169.254.169.254/latest/user-data`                                             |
| Azure (WIP)    | `http://169.254.169.254/metadata/instance/compute/customData?api-version=2019-06-04"` |

Note, in particular, that workers are not typically started with static Taskcluster credentials.
While it remains possible to do so, it is not recommended and will result in a "ghost" worker that claims work but does not appear in the worker-manager.

### Registration

At startup, a worker must register with the worker manager by calling [`workerManager.registerWorker`](/docs/reference/core/worker-manager/api#registerWorker).
This call requires the information described above, as well as an "identity proof".
This value allows the worker manager service to be sure that the caller truly is the intended worker, and not an impostor.
Since `registerWorker` does not require Taskcluster credentials, this proof is a critical access-control mechanism and must be implemented carefully.
The details vary by provider.

If successful, the `registerWorker` call returns a set of Taskcluster credentials and an `expires` datestamp when those credentials will expire.
These credentials have the scopes required by the worker for its operation, including scopes to get secrets and to call `queue.claimWork`.

It is the responsibility of the worker to finish its work before the credentials expire.

Depending on the provider, `registerWorker` may be called multiple times for the same worker, or may only be called once.

## Reregistration

The worker may reregister itself to renew its credentials with the worker manager by calling
[`workerManager.reregister`](/docs/reference/core/worker-manager/api#reregisterWorker) and
supplying it with a one time usage `secret`. The secret value will have been either last generated
in `registerWorker` (in the case of a newly registered worker) or `reregisterWorker`.
The expiration time of the new credentials comes from the worker pool configuration via `reregistrationTimeout`
which gets set when calling [`workerManager.registerWorker`](/docs/reference/core/worker-manager/api#registerWorker).
The default behavior, when `reregistrationTimeout` is omitted, is to extend the credentials by 96 hours.

## Queue Inactivity Timeout

To make sure that spawned workers are not stuck in a "zombie" state, the worker-manager will check with queue service
to see if there was any recent activity from a given worker.

Unfortunately, it is not always possible to handle critical errors gracefully on a worker itself. For example,
if worker process is being terminated with an out of memory error, it is not possible to catch it and report it to the worker-manager.
Also, when an image is not configured properly, the worker might be able to start and register, but would fail to call `queue.claimWork`.

In such cases, worker-manager will give `lifecycle.queueInactivityTimeout` seconds to a worker before it is going to be terminated.

Queue service keeps track of worker interactions and stores internally a timestamp when worker first claimed work and
when it was last active. That information is being used by worker manager to determine if worker is still active or not.

Static workers and quarantines workers are not affected by this timeout.

## Worker Configuration

Worker images and hosts should generally be kept as generic as possible, with configuration provided via the worker-manager.
This permits centralized control and easier modification.

Workers can get their configuration from a few places, varying somewhat depending on the provider:

* On-Image Configuration -- This is typically used for information about pathnames and devices that are specific to the host where the worker is running.
* User-data -- Cloud-based providers can provide configuration in the user-data.
  This is typically used for information specific to the worker pool, such as worker implementation version or enabled features.
* Secrets -- Worker configuration can be stored in the secrets service as well.
  By convention these secrets are named `worker-pool:<workerPoolId>`, and the worker-manager-provided credentials have the appropriate `secret:get:` scope to fetch that secret.
  Secrets are typically used for configuration that cannot be stored in the world-readable worker-pool configuration.

### Error Reporting

The worker-manager service maintains a list of errors that have occurred for each worker pool.
This list is helpful for admins modifying the worker-pool configuration to see quickly whether those modifications have failed.
In some cases, the provider can determine that an error has occurred, for example when a particular cloud instance type is not available.
In other cases, instances start up successfully but cannot execute tasks, for example because the instance has too little disk space.

In such cases, the worker can call [`workerManager.reportWorkerError`](/docs/reference/core/worker-manager/api#reportWorkerError) to add to the worker pool's list of errors.
Workers should *only* use this method to report errors that might be related to the worker-pool configuration.
This could include worker start-up issues, but does not include failed tasks or transient issues like network errors.

<Warning>
Errors are publicly visible.
Workers should not include any secrets or other sensitive information in the error report.
</Warning>
