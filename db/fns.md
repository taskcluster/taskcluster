# Stored Functions
<!-- AUTOGENERATED CONTENT; DO NOT EDIT -->

 * [auth functions](#auth)
   * [`create_client`](#create_client)
   * [`delete_client`](#delete_client)
   * [`expire_clients`](#expire_clients)
   * [`get_client`](#get_client)
   * [`get_clients`](#get_clients)
   * [`get_roles`](#get_roles)
   * [`modify_roles`](#modify_roles)
   * [`update_client`](#update_client)
   * [`update_client_last_used`](#update_client_last_used)
 * [github functions](#github)
   * [`create_github_build`](#create_github_build)
   * [`create_github_check`](#create_github_check)
   * [`delete_github_build`](#delete_github_build)
   * [`get_github_build`](#get_github_build)
   * [`get_github_builds`](#get_github_builds)
   * [`get_github_check_by_run_id`](#get_github_check_by_run_id)
   * [`get_github_check_by_task_id`](#get_github_check_by_task_id)
   * [`get_github_integration`](#get_github_integration)
   * [`get_github_integrations`](#get_github_integrations)
   * [`set_github_build_state`](#set_github_build_state)
   * [`upsert_github_integration`](#upsert_github_integration)
 * [hooks functions](#hooks)
   * [`create_hook`](#create_hook)
   * [`create_hooks_queue`](#create_hooks_queue)
   * [`create_last_fire`](#create_last_fire)
   * [`delete_hook`](#delete_hook)
   * [`delete_hooks_queue`](#delete_hooks_queue)
   * [`delete_last_fires`](#delete_last_fires)
   * [`expire_last_fires`](#expire_last_fires)
   * [`get_hook`](#get_hook)
   * [`get_hooks`](#get_hooks)
   * [`get_hooks_queues`](#get_hooks_queues)
   * [`get_last_fire`](#get_last_fire)
   * [`get_last_fires`](#get_last_fires)
   * [`update_hook`](#update_hook)
   * [`update_hooks_queue_bindings`](#update_hooks_queue_bindings)
 * [index functions](#index)
   * [`create_index_namespace`](#create_index_namespace)
   * [`create_indexed_task`](#create_indexed_task)
   * [`delete_indexed_task`](#delete_indexed_task)
   * [`expire_index_namespaces`](#expire_index_namespaces)
   * [`expire_indexed_tasks`](#expire_indexed_tasks)
   * [`get_index_namespace`](#get_index_namespace)
   * [`get_index_namespaces`](#get_index_namespaces)
   * [`get_indexed_task`](#get_indexed_task)
   * [`get_indexed_tasks`](#get_indexed_tasks)
   * [`update_index_namespace`](#update_index_namespace)
   * [`update_indexed_task`](#update_indexed_task)
 * [notify functions](#notify)
   * [`add_denylist_address`](#add_denylist_address)
   * [`all_denylist_addresses`](#all_denylist_addresses)
   * [`delete_denylist_address`](#delete_denylist_address)
   * [`exists_denylist_address`](#exists_denylist_address)
 * [object functions](#object)
   * [`add_object_hashes`](#add_object_hashes)
   * [`create_object_for_upload`](#create_object_for_upload)
   * [`delete_object`](#delete_object)
   * [`get_expired_objects`](#get_expired_objects)
   * [`get_object_hashes`](#get_object_hashes)
   * [`get_object_with_upload`](#get_object_with_upload)
   * [`object_upload_complete`](#object_upload_complete)
 * [purge_cache functions](#purge_cache)
   * [`all_purge_requests_wpid`](#all_purge_requests_wpid)
   * [`expire_cache_purges`](#expire_cache_purges)
   * [`purge_cache_wpid`](#purge_cache_wpid)
   * [`purge_requests_wpid`](#purge_requests_wpid)
 * [queue functions](#queue)
   * [`add_task_dependency`](#add_task_dependency)
   * [`azure_queue_count`](#azure_queue_count)
   * [`azure_queue_delete`](#azure_queue_delete)
   * [`azure_queue_delete_expired`](#azure_queue_delete_expired)
   * [`azure_queue_get`](#azure_queue_get)
   * [`azure_queue_put`](#azure_queue_put)
   * [`azure_queue_update`](#azure_queue_update)
   * [`cancel_task`](#cancel_task)
   * [`check_task_claim`](#check_task_claim)
   * [`claim_task`](#claim_task)
   * [`create_queue_artifact`](#create_queue_artifact)
   * [`create_task_projid`](#create_task_projid)
   * [`delete_queue_artifact`](#delete_queue_artifact)
   * [`delete_queue_provisioner`](#delete_queue_provisioner)
   * [`delete_queue_worker_type`](#delete_queue_worker_type)
   * [`ensure_task_group`](#ensure_task_group)
   * [`expire_queue_workers`](#expire_queue_workers)
   * [`expire_task_dependencies`](#expire_task_dependencies)
   * [`expire_task_groups`](#expire_task_groups)
   * [`expire_task_queues`](#expire_task_queues)
   * [`expire_tasks`](#expire_tasks)
   * [`get_dependent_tasks`](#get_dependent_tasks)
   * [`get_queue_artifact`](#get_queue_artifact)
   * [`get_queue_artifacts_paginated`](#get_queue_artifacts_paginated)
   * [`get_task_group`](#get_task_group)
   * [`get_task_projid`](#get_task_projid)
   * [`get_task_queue`](#get_task_queue)
   * [`get_task_queues`](#get_task_queues)
   * [`get_tasks_by_task_group_projid`](#get_tasks_by_task_group_projid)
   * [`is_task_blocked`](#is_task_blocked)
   * [`is_task_group_active`](#is_task_group_active)
   * [`mark_task_ever_resolved`](#mark_task_ever_resolved)
   * [`quarantine_queue_worker_with_last_date_active`](#quarantine_queue_worker_with_last_date_active)
   * [`queue_artifact_present`](#queue_artifact_present)
   * [`queue_worker_seen_with_last_date_active`](#queue_worker_seen_with_last_date_active)
   * [`queue_worker_task_seen`](#queue_worker_task_seen)
   * [`reclaim_task`](#reclaim_task)
   * [`remove_task`](#remove_task)
   * [`remove_task_dependency`](#remove_task_dependency)
   * [`rerun_task`](#rerun_task)
   * [`resolve_task`](#resolve_task)
   * [`resolve_task_at_deadline`](#resolve_task_at_deadline)
   * [`satisfy_task_dependency`](#satisfy_task_dependency)
   * [`schedule_task`](#schedule_task)
   * [`task_queue_seen`](#task_queue_seen)
   * [`update_queue_artifact_2`](#update_queue_artifact_2)
 * [secrets functions](#secrets)
   * [`delete_secret`](#delete_secret)
   * [`expire_secrets`](#expire_secrets)
   * [`get_secret`](#get_secret)
   * [`get_secrets`](#get_secrets)
   * [`upsert_secret`](#upsert_secret)
 * [web_server functions](#web_server)
   * [`add_github_access_token`](#add_github_access_token)
   * [`create_access_token`](#create_access_token)
   * [`create_authorization_code`](#create_authorization_code)
   * [`expire_access_tokens`](#expire_access_tokens)
   * [`expire_authorization_codes`](#expire_authorization_codes)
   * [`expire_sessions`](#expire_sessions)
   * [`get_access_token`](#get_access_token)
   * [`get_authorization_code`](#get_authorization_code)
   * [`load_github_access_token`](#load_github_access_token)
   * [`session_add`](#session_add)
   * [`session_load`](#session_load)
   * [`session_remove`](#session_remove)
   * [`session_touch`](#session_touch)
 * [worker_manager functions](#worker_manager)
   * [`create_worker`](#create_worker)
   * [`create_worker_pool`](#create_worker_pool)
   * [`create_worker_pool_error`](#create_worker_pool_error)
   * [`delete_worker`](#delete_worker)
   * [`delete_worker_pool`](#delete_worker_pool)
   * [`delete_worker_pool_error`](#delete_worker_pool_error)
   * [`expire_worker_pool_errors`](#expire_worker_pool_errors)
   * [`expire_worker_pools`](#expire_worker_pools)
   * [`expire_workers`](#expire_workers)
   * [`get_non_stopped_workers_quntil_providers`](#get_non_stopped_workers_quntil_providers)
   * [`get_queue_worker_with_wm_join`](#get_queue_worker_with_wm_join)
   * [`get_queue_workers_with_wm_join`](#get_queue_workers_with_wm_join)
   * [`get_task_queue_wm_2`](#get_task_queue_wm_2)
   * [`get_task_queues_wm`](#get_task_queues_wm)
   * [`get_worker_2`](#get_worker_2)
   * [`get_worker_pool_error`](#get_worker_pool_error)
   * [`get_worker_pool_errors_for_worker_pool`](#get_worker_pool_errors_for_worker_pool)
   * [`get_worker_pool_with_capacity_and_counts_by_state`](#get_worker_pool_with_capacity_and_counts_by_state)
   * [`get_worker_pools_with_capacity_and_counts_by_state`](#get_worker_pools_with_capacity_and_counts_by_state)
   * [`get_workers_without_provider_data`](#get_workers_without_provider_data)
   * [`remove_worker_pool_previous_provider_id`](#remove_worker_pool_previous_provider_id)
   * [`update_worker_2`](#update_worker_2)
   * [`update_worker_pool_provider_data`](#update_worker_pool_provider_data)
   * [`update_worker_pool_with_capacity_and_counts_by_state`](#update_worker_pool_with_capacity_and_counts_by_state)

## auth

* [`create_client`](#create_client)
* [`delete_client`](#delete_client)
* [`expire_clients`](#expire_clients)
* [`get_client`](#get_client)
* [`get_clients`](#get_clients)
* [`get_roles`](#get_roles)
* [`modify_roles`](#modify_roles)
* [`update_client`](#update_client)
* [`update_client_last_used`](#update_client_last_used)

### create_client

* *Mode*: write
* *Arguments*:
  * `client_id_in text`
  * `description_in text`
  * `encrypted_access_token_in jsonb`
  * `expires_in timestamptz`
  * `disabled_in boolean`
  * `scopes_in jsonb`
  * `delete_on_expiration_in boolean`
* *Returns*: `void`
* *Last defined on version*: 41

Create a new client.  The created and last_.. timestamps are all
initialized to the current time.  If the row exists but scopes,
description, and expires match, disabled is false, and it was created in
the last 15 minutes, then nothing is changed.  Otherwise, a
UNIQUE_VIOLATION is raised.

### delete_client

* *Mode*: write
* *Arguments*:
  * `client_id_in text`
* *Returns*: `void`
* *Last defined on version*: 41

Delete the given client.  If the client does not exist, nothing happens.

### expire_clients

* *Mode*: write
* *Arguments*:
* *Returns*: `integer`
* *Last defined on version*: 41

Delete all clients with an 'expires' in the past and with 'delete_on_expiration' set.

### get_client

* *Mode*: read
* *Arguments*:
  * `client_id_in text`
* *Returns*: `table`
  * `   client_id text`
  * `  description text`
  * `  encrypted_access_token jsonb`
  * `  expires timestamptz`
  * `  disabled boolean`
  * `  scopes jsonb`
  * `  created timestamptz`
  * `  last_modified timestamptz`
  * `  last_date_used timestamptz`
  * `  last_rotated timestamptz`
  * `  delete_on_expiration boolean `
* *Last defined on version*: 41

Get a client. Returns an empty set if the client does not exist.

### get_clients

* *Mode*: read
* *Arguments*:
  * `prefix_in text`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `   client_id text`
  * `  description text`
  * `  encrypted_access_token jsonb`
  * `  expires timestamptz`
  * `  disabled boolean`
  * `  scopes jsonb`
  * `  created timestamptz`
  * `  last_modified timestamptz`
  * `  last_date_used timestamptz`
  * `  last_rotated timestamptz`
  * `  delete_on_expiration boolean `
* *Last defined on version*: 41

Get clients, ordered by client_id.   If specified, only clients with
client_id beginning with `prefix` are returned.  If the pagination
arguments are both NULL, all rows are returned.  Otherwise, page_size
rows are returned at offset page_offset.

### get_roles

* *Mode*: read
* *Arguments*:
* *Returns*: `table`
  * `role_id text`
  * `scopes jsonb`
  * `created timestamptz`
  * `description text`
  * `last_modified timestamptz`
  * `etag uuid`
* *Last defined on version*: 25

Get the full set of roles.  Each result row has an etag, but all such
etags will be the same, representing the etag for the most recent
modification of the table.  Results are sorted by role_id.

### modify_roles

* *Mode*: write
* *Arguments*:
  * `roles_in jsonb`
  * `old_etag_in uuid`
* *Returns*: `void`
* *Last defined on version*: 25

Replace the current set of roles entirely with the given set of roles, if the current etag matches the existing etag.
The role objects are specified with underscore spelling (`role_id`).
If the etag has changed, this returns P0004 signalling that the caller should fetch a fresh set of roles and try again.
If there are no existing roles, then the old etag is not used.

### update_client

* *Mode*: write
* *Arguments*:
  * `client_id_in text`
  * `description_in text`
  * `encrypted_access_token_in jsonb`
  * `expires_in timestamptz`
  * `disabled_in boolean`
  * `scopes_in jsonb`
  * `delete_on_expiration_in boolean`
* *Returns*: `table`
  * `   client_id text`
  * `  description text`
  * `  encrypted_access_token jsonb`
  * `  expires timestamptz`
  * `  disabled boolean`
  * `  scopes jsonb`
  * `  created timestamptz`
  * `  last_modified timestamptz`
  * `  last_date_used timestamptz`
  * `  last_rotated timestamptz`
  * `  delete_on_expiration boolean `
* *Last defined on version*: 41

Update an existing client, returning the updated client or, if no such client
exists, an empty set.  This does not implement optimistic concurrency: any non-null
arguments to this function will overwrite existing values.  The last_modified
column is updated automatically, as is last_rotated if the access token is set.

### update_client_last_used

* *Mode*: write
* *Arguments*:
  * `client_id_in text`
* *Returns*: `void`
* *Last defined on version*: 41

Indicate that this client has been recently used, updating its last_date_used field.
Does nothing if the client does not exist.

## github

* [`create_github_build`](#create_github_build)
* [`create_github_check`](#create_github_check)
* [`delete_github_build`](#delete_github_build)
* [`get_github_build`](#get_github_build)
* [`get_github_builds`](#get_github_builds)
* [`get_github_check_by_run_id`](#get_github_check_by_run_id)
* [`get_github_check_by_task_id`](#get_github_check_by_task_id)
* [`get_github_integration`](#get_github_integration)
* [`get_github_integrations`](#get_github_integrations)
* [`set_github_build_state`](#set_github_build_state)
* [`upsert_github_integration`](#upsert_github_integration)

### create_github_build

* *Mode*: write
* *Arguments*:
  * `organization_in text`
  * `repository_in text`
  * `sha_in text`
  * `task_group_id_in text`
  * `state_in text`
  * `created_in timestamptz`
  * `updated_in timestamptz`
  * `installation_id_in integer`
  * `event_type_in text`
  * `event_id_in text`
* *Returns*: `void`
* *Last defined on version*: 23

Create a new github build.  Raises UNIQUE_VIOLATION if the pool already exists.

### create_github_check

* *Mode*: write
* *Arguments*:
  * `task_group_id_in text`
  * `task_id_in text`
  * `check_suite_id_in text`
  * `check_run_id_in text`
* *Returns*: `void`
* *Last defined on version*: 58

Upsert a single check.

### delete_github_build

* *Mode*: write
* *Arguments*:
  * `task_group_id_in text`
* *Returns*: `void`
* *Last defined on version*: 23

Delete a github build.

### get_github_build

* *Mode*: read
* *Arguments*:
  * `task_group_id_in text`
* *Returns*: `table`
  * `organization text`
  * `repository text`
  * `sha text`
  * `task_group_id text`
  * `state text`
  * `created timestamptz`
  * `updated timestamptz`
  * `installation_id integer`
  * `event_type text`
  * `event_id text`
  * `etag uuid`
* *Last defined on version*: 49

Get a github build. The returned table will have one or zero rows.

### get_github_builds

* *Mode*: read
* *Arguments*:
  * `page_size_in integer`
  * `page_offset_in integer`
  * `organization_in text`
  * `repository_in text`
  * `sha_in text`
* *Returns*: `table`
  * `organization text`
  * `repository text`
  * `sha text`
  * `task_group_id text`
  * `state text`
  * `created timestamptz`
  * `updated timestamptz`
  * `installation_id integer`
  * `event_type text`
  * `event_id text`
  * `etag uuid`
* *Last defined on version*: 49

Get github builds.

### get_github_check_by_run_id

* *Mode*: read
* *Arguments*:
  * `check_suite_id_in text`
  * `check_run_id_in text`
* *Returns*: `table`
  * `   task_group_id text`
  * `  task_id text`
  * `  check_suite_id text`
  * `  check_run_id text `
* *Last defined on version*: 76

Get github check run id and check suite id

### get_github_check_by_task_id

* *Mode*: read
* *Arguments*:
  * `task_id_in text`
* *Returns*: `table`
  * `task_group_id text`
  * `task_id text`
  * `check_suite_id text`
  * `check_run_id text`
* *Last defined on version*: 37

Get a single check from a task_id.

### get_github_integration

* *Mode*: read
* *Arguments*:
  * `owner_in text`
* *Returns*: `table`
  * `owner text`
  * `installation_id integer`
* *Last defined on version*: 36

Get a single integration by owner.

### get_github_integrations

* *Mode*: read
* *Arguments*:
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `owner text`
  * `installation_id integer`
* *Last defined on version*: 36

Get a list of integrations.

### set_github_build_state

* *Mode*: write
* *Arguments*:
  * `task_group_id_in text`
  * `state_in text`
* *Returns*: `void`
* *Last defined on version*: 49

Only update the state of a build and update the `updated` timestamp

### upsert_github_integration

* *Mode*: write
* *Arguments*:
  * `owner_in text`
  * `installation_id_in integer`
* *Returns*: `void`
* *Last defined on version*: 36

Create a single integration.

## hooks

* [`create_hook`](#create_hook)
* [`create_hooks_queue`](#create_hooks_queue)
* [`create_last_fire`](#create_last_fire)
* [`delete_hook`](#delete_hook)
* [`delete_hooks_queue`](#delete_hooks_queue)
* [`delete_last_fires`](#delete_last_fires)
* [`expire_last_fires`](#expire_last_fires)
* [`get_hook`](#get_hook)
* [`get_hooks`](#get_hooks)
* [`get_hooks_queues`](#get_hooks_queues)
* [`get_last_fire`](#get_last_fire)
* [`get_last_fires`](#get_last_fires)
* [`update_hook`](#update_hook)
* [`update_hooks_queue_bindings`](#update_hooks_queue_bindings)

### create_hook

* *Mode*: write
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
  * `metadata_in jsonb`
  * `task_in jsonb`
  * `bindings_in jsonb`
  * `schedule_in jsonb`
  * `encrypted_trigger_token_in jsonb`
  * `encrypted_next_task_id_in jsonb`
  * `next_scheduled_date_in timestamptz`
  * `trigger_schema_in jsonb`
* *Returns*: `table`
  * `hook_group_id text`
  * `hook_id text`
  * `metadata jsonb`
  * `task jsonb`
  * `bindings jsonb`
  * `schedule jsonb`
  * `encrypted_trigger_token jsonb`
  * `encrypted_next_task_id jsonb`
  * `next_scheduled_date timestamptz`
  * `trigger_schema jsonb`
* *Last defined on version*: 35

Create a new hook. Raises UNIQUE_VIOLATION if the artifact already exists.
Returns the newly created hook.

### create_hooks_queue

* *Mode*: write
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
  * `queue_name_in text`
  * `bindings_in jsonb`
* *Returns*: `uuid`
* *Last defined on version*: 49

Create a new hooks queue. Raises UNIQUE_VIOLATION if the hook already exists.

### create_last_fire

* *Mode*: write
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
  * `fired_by_in text`
  * `task_id_in text`
  * `task_create_time_in timestamptz`
  * `result_in text`
  * `error_in text`
* *Returns*: `uuid`
* *Last defined on version*: 49

Create a new hook last fire. Raises UNIQUE_VIOLATION if the hook already exists.

### delete_hook

* *Mode*: write
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
* *Returns*: `void`
* *Last defined on version*: 35

Delete a hook.

### delete_hooks_queue

* *Mode*: write
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
* *Returns*: `void`
* *Last defined on version*: 49

Delete a hooks queue.

### delete_last_fires

* *Mode*: write
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
* *Returns*: `void`
* *Last defined on version*: 32

Delete last fires that match a given `hook_group_id` and `hook_id`.

### expire_last_fires

* *Mode*: write
* *Arguments*:
* *Returns*: `integer`
* *Last defined on version*: 32

Expire last fires that are older than a year.
Returns a count of rows that have been deleted.

### get_hook

* *Mode*: read
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
* *Returns*: `table`
  * `hook_group_id text`
  * `hook_id text`
  * `metadata jsonb`
  * `task jsonb`
  * `bindings jsonb`
  * `schedule jsonb`
  * `encrypted_trigger_token jsonb`
  * `encrypted_next_task_id jsonb`
  * `next_scheduled_date timestamptz`
  * `trigger_schema jsonb`
* *Last defined on version*: 35

Get a hook. The returned table will have one or zero rows.

### get_hooks

* *Mode*: read
* *Arguments*:
  * `hook_group_id_in text`
  * `next_scheduled_date_in timestamptz`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `hook_group_id text`
  * `hook_id text`
  * `metadata jsonb`
  * `task jsonb`
  * `bindings jsonb`
  * `schedule jsonb`
  * `encrypted_trigger_token jsonb`
  * `encrypted_next_task_id jsonb`
  * `next_scheduled_date timestamptz`
  * `trigger_schema jsonb`
* *Last defined on version*: 35

Get existing hooks filtered by the optional `hook_group_id`,
ordered by the `hook_group_id` and `hook_id`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### get_hooks_queues

* *Mode*: read
* *Arguments*:
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `hook_group_id text`
  * `hook_id text`
  * `queue_name text`
  * `bindings jsonb`
  * `etag uuid`
* *Last defined on version*: 49

Get hooks queues ordered by `hook_group_id` and `hook_id`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### get_last_fire

* *Mode*: read
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
  * `task_id_in text`
* *Returns*: `table`
  * `hook_group_id text`
  * `hook_id text`
  * `fired_by text`
  * `task_id text`
  * `task_create_time timestamptz`
  * `result text`
  * `error text`
  * `etag uuid`
* *Last defined on version*: 49

Get a hook last fire.

### get_last_fires

* *Mode*: read
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `hook_group_id text`
  * `hook_id text`
  * `fired_by text`
  * `task_id text`
  * `task_create_time timestamptz`
  * `result text`
  * `error text`
  * `etag uuid`
* *Last defined on version*: 49

Get hooks last fires filtered by the `hook_group_id` and `hook_id` arguments,
ordered by `hook_group_id`, `hook_id`, and  `worker_id`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### update_hook

* *Mode*: write
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
  * `metadata_in jsonb`
  * `task_in jsonb`
  * `bindings_in jsonb`
  * `schedule_in jsonb`
  * `encrypted_trigger_token_in jsonb`
  * `encrypted_next_task_id_in jsonb`
  * `next_scheduled_date_in timestamptz`
  * `trigger_schema_in jsonb`
* *Returns*: `table`
  * `hook_group_id text`
  * `hook_id text`
  * `metadata jsonb`
  * `task jsonb`
  * `bindings jsonb`
  * `schedule jsonb`
  * `encrypted_trigger_token jsonb`
  * `encrypted_next_task_id jsonb`
  * `next_scheduled_date timestamptz`
  * `trigger_schema jsonb`
* *Last defined on version*: 35

Update a queue artifact.
Returns the up-to-date hook row that have the same hook group id and hook id.

### update_hooks_queue_bindings

* *Mode*: write
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
  * `bindings_in jsonb`
* *Returns*: `table`
  * `hook_group_id text`
  * `hook_id text`
  * `queue_name text`
  * `bindings jsonb`
  * `etag uuid`
* *Last defined on version*: 49

Update bindings of a hooks queue. If no such queue exists,
the return value is an empty set.

## index

* [`create_index_namespace`](#create_index_namespace)
* [`create_indexed_task`](#create_indexed_task)
* [`delete_indexed_task`](#delete_indexed_task)
* [`expire_index_namespaces`](#expire_index_namespaces)
* [`expire_indexed_tasks`](#expire_indexed_tasks)
* [`get_index_namespace`](#get_index_namespace)
* [`get_index_namespaces`](#get_index_namespaces)
* [`get_indexed_task`](#get_indexed_task)
* [`get_indexed_tasks`](#get_indexed_tasks)
* [`update_index_namespace`](#update_index_namespace)
* [`update_indexed_task`](#update_indexed_task)

### create_index_namespace

* *Mode*: write
* *Arguments*:
  * `parent_in text`
  * `name_in text`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `parent text`
  * `name text`
  * `expires timestamptz`
* *Last defined on version*: 26

Create a new namespace. Raises UNIQUE_VIOLATION if the namespace already exists.
Returns the newly created namespace.

### create_indexed_task

* *Mode*: write
* *Arguments*:
  * `namespace_in text`
  * `name_in text`
  * `rank_in integer`
  * `task_id_in text`
  * `data_in jsonb`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `namespace text`
  * `name text`
  * `rank integer`
  * `task_id text`
  * `data jsonb`
  * `expires timestamptz`
* *Last defined on version*: 26

Create a new indexed task. Raises UNIQUE_VIOLATION if the indexed task already exists.
Returns the newly created indexed task.

### delete_indexed_task

* *Mode*: write
* *Arguments*:
  * `namespace_in text`
  * `name_in text`
* *Returns*: `void`
* *Last defined on version*: 65

Delete the named task from the index.  Returns succesfully even if the named
task does not exist.

### expire_index_namespaces

* *Mode*: write
* *Arguments*:
* *Returns*: `integer`
* *Last defined on version*: 26

Expire index_namespaces that come before the current time.
Returns a count of rows that have been deleted.

### expire_indexed_tasks

* *Mode*: write
* *Arguments*:
* *Returns*: `integer`
* *Last defined on version*: 26

Expire indexed tasks that come before the current time.
Returns a count of rows that have been deleted.

### get_index_namespace

* *Mode*: read
* *Arguments*:
  * `parent_in text`
  * `name_in text`
* *Returns*: `table`
  * `parent text`
  * `name text`
  * `expires timestamptz`
* *Last defined on version*: 26

Get a namespace. The returned table will have one or zero rows.

### get_index_namespaces

* *Mode*: read
* *Arguments*:
  * `parent_in text`
  * `name_in text`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `parent text`
  * `name text`
  * `expires timestamptz`
* *Last defined on version*: 26

Get existing index_namespaces filtered by the optional arguments,
ordered by the `parent` and `name`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### get_indexed_task

* *Mode*: read
* *Arguments*:
  * `namespace_in text`
  * `name_in text`
* *Returns*: `table`
  * `namespace text`
  * `name text`
  * `rank integer`
  * `task_id text`
  * `data jsonb`
  * `expires timestamptz`
* *Last defined on version*: 26

Get an indexed task. The returned table will have one or zero rows.

### get_indexed_tasks

* *Mode*: read
* *Arguments*:
  * `namespace_in text`
  * `name_in text`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `namespace text`
  * `name text`
  * `rank integer`
  * `task_id text`
  * `data jsonb`
  * `expires timestamptz`
* *Last defined on version*: 26

Get existing indexed tasks filtered by the optional arguments,
ordered by the `namespace` and `name`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### update_index_namespace

* *Mode*: write
* *Arguments*:
  * `parent_in text`
  * `name_in text`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `parent text`
  * `name text`
  * `expires timestamptz`
* *Last defined on version*: 26

Update a namespace.
Returns the up-to-date namespace row that have the same parent and name.
If the row is not found then an exception with code 'P0002' is thrown.

### update_indexed_task

* *Mode*: write
* *Arguments*:
  * `namespace_in text`
  * `name_in text`
  * `rank_in integer`
  * `task_id_in text`
  * `data_in jsonb`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `namespace text`
  * `name text`
  * `rank integer`
  * `task_id text`
  * `data jsonb`
  * `expires timestamptz`
* *Last defined on version*: 26

Update an indexed task.
Returns the up-to-date indexed task row that have the same namespace and name.

## notify

* [`add_denylist_address`](#add_denylist_address)
* [`all_denylist_addresses`](#all_denylist_addresses)
* [`delete_denylist_address`](#delete_denylist_address)
* [`exists_denylist_address`](#exists_denylist_address)

### add_denylist_address

* *Mode*: write
* *Arguments*:
  * `notification_type_in text`
  * `notification_address_in text`
* *Returns*: `void`
* *Last defined on version*: 49

If the denylist address already exists, this is a no-op. Otherwise, add the denylist
address for the taskcluster-notify service, with a new random etag.

### all_denylist_addresses

* *Mode*: read
* *Arguments*:
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `notification_type text`
  * `notification_address text`
* *Last defined on version*: 17

List all denylist addresses for the taskcluster-notify service.

### delete_denylist_address

* *Mode*: write
* *Arguments*:
  * `notification_type_in text`
  * `notification_address_in text`
* *Returns*: `integer`
* *Last defined on version*: 17

Delete a denylist address for the taskcluster-notify service.
Returns number of rows deleted (0 or 1).

### exists_denylist_address

* *Mode*: read
* *Arguments*:
  * `notification_type_in text`
  * `notification_address_in text`
* *Returns*: `boolean`
* *Last defined on version*: 17

Returns a boolean indicating whether the denylist type/address exists.

## object

* [`add_object_hashes`](#add_object_hashes)
* [`create_object_for_upload`](#create_object_for_upload)
* [`delete_object`](#delete_object)
* [`get_expired_objects`](#get_expired_objects)
* [`get_object_hashes`](#get_object_hashes)
* [`get_object_with_upload`](#get_object_with_upload)
* [`object_upload_complete`](#object_upload_complete)

### add_object_hashes

* *Mode*: write
* *Arguments*:
  * `name_in text`
  * `hashes_in jsonb`
* *Returns*: `void`
* *Last defined on version*: 67

Add the given hashes, of the form `{algorithm: hash}`, to the named
object.  The named object must already exist.  If any of the given
algorithms already exist in the table, then the hash must match exactly.
This function raises a CHECK_VIOLATION if the object's upload has been
finished (upload_id is null) or FOREIGN_KEY_VIOLATION if the object does
not exist.

### create_object_for_upload

* *Mode*: write
* *Arguments*:
  * `name_in text`
  * `project_id_in text`
  * `backend_id_in text`
  * `upload_id_in text`
  * `upload_expires_in timestamptz`
  * `data_in jsonb`
  * `expires_in timestamptz`
* *Returns*: `void`
* *Last defined on version*: 56

Create an object record ready for upload.

This method is idempotent, and will succeed if called multiple times with
the same parameters, as long as `upload_id` is still set (that is, until
the upload is completed).  Otherwise it will raise a UNIQUE_VIOLATION
exception.  `upload_expires_in` is excluded from this comparison.

### delete_object

* *Mode*: write
* *Arguments*:
  * `name_in text`
* *Returns*: `void`
* *Last defined on version*: 54

Delete an object.

### get_expired_objects

* *Mode*: read
* *Arguments*:
  * `limit_in integer`
  * `start_at_in text`
* *Returns*: `table`
  * `name text`
  * `data jsonb`
  * `project_id text`
  * `backend_id text`
  * `expires timestamptz`
* *Last defined on version*: 56

Get objects with an expiration before the current time.  If given, only
objects with a name greater than `start_at_in` are returned.  The
`limit_in` argument limits the number of results returned.  This returns
both expired objects (expires < now) and expired uploads (upload_expires
< now).

### get_object_hashes

* *Mode*: read
* *Arguments*:
  * `name_in text`
* *Returns*: `table`
  * ` algorithm text`
  * `hash text `
* *Last defined on version*: 67

Get all hashes for the named object.  If the given object has no hashes,
or doesn't exist, this function returns an empty result.

### get_object_with_upload

* *Mode*: read
* *Arguments*:
  * `name_in text`
* *Returns*: `table`
  * `name text`
  * `data jsonb`
  * `project_id text`
  * `backend_id text`
  * `upload_id text`
  * `upload_expires timestamptz`
  * `expires timestamptz`
* *Last defined on version*: 56

Get an object by name, or an empty set if no such object exists.

### object_upload_complete

* *Mode*: write
* *Arguments*:
  * `name_in text`
  * `upload_id_in text`
* *Returns*: `void`
* *Last defined on version*: 56

Mark an object as uploaded and ready for download.

This method is idempotent, and will succeed if the object is already ready
for download.

## purge_cache

* [`all_purge_requests_wpid`](#all_purge_requests_wpid)
* [`expire_cache_purges`](#expire_cache_purges)
* [`purge_cache_wpid`](#purge_cache_wpid)
* [`purge_requests_wpid`](#purge_requests_wpid)

### all_purge_requests_wpid

* *Mode*: read
* *Arguments*:
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `worker_pool_id text`
  * `cache_name text`
  * `before timestamptz`
* *Last defined on version*: 50

View all active purge requests.

### expire_cache_purges

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`
* *Last defined on version*: 9

Expire cache purges that come before `expires_in`.
Returns a count of rows that have been deleted.

### purge_cache_wpid

* *Mode*: write
* *Arguments*:
  * `worker_pool_id_in text`
  * `cache_name_in text`
  * `before_in timestamptz`
  * `expires_in timestamptz`
* *Returns*: `void`
* *Last defined on version*: 50

Publish a request to purge caches with name `cache_name_in`
on `provisioner_id_in`/`worker_type_in` workers.

### purge_requests_wpid

* *Mode*: read
* *Arguments*:
  * `worker_pool_id_in text`
* *Returns*: `table`
  * `worker_pool_id text`
  * `cache_name text`
  * `before timestamptz`
* *Last defined on version*: 50

List the caches for this `provisioner_id_in`/`worker_type_in`.

## queue

* [`add_task_dependency`](#add_task_dependency)
* [`azure_queue_count`](#azure_queue_count)
* [`azure_queue_delete`](#azure_queue_delete)
* [`azure_queue_delete_expired`](#azure_queue_delete_expired)
* [`azure_queue_get`](#azure_queue_get)
* [`azure_queue_put`](#azure_queue_put)
* [`azure_queue_update`](#azure_queue_update)
* [`cancel_task`](#cancel_task)
* [`check_task_claim`](#check_task_claim)
* [`claim_task`](#claim_task)
* [`create_queue_artifact`](#create_queue_artifact)
* [`create_task_projid`](#create_task_projid)
* [`delete_queue_artifact`](#delete_queue_artifact)
* [`delete_queue_provisioner`](#delete_queue_provisioner)
* [`delete_queue_worker_type`](#delete_queue_worker_type)
* [`ensure_task_group`](#ensure_task_group)
* [`expire_queue_workers`](#expire_queue_workers)
* [`expire_task_dependencies`](#expire_task_dependencies)
* [`expire_task_groups`](#expire_task_groups)
* [`expire_task_queues`](#expire_task_queues)
* [`expire_tasks`](#expire_tasks)
* [`get_dependent_tasks`](#get_dependent_tasks)
* [`get_queue_artifact`](#get_queue_artifact)
* [`get_queue_artifacts_paginated`](#get_queue_artifacts_paginated)
* [`get_task_group`](#get_task_group)
* [`get_task_projid`](#get_task_projid)
* [`get_task_queue`](#get_task_queue)
* [`get_task_queues`](#get_task_queues)
* [`get_tasks_by_task_group_projid`](#get_tasks_by_task_group_projid)
* [`is_task_blocked`](#is_task_blocked)
* [`is_task_group_active`](#is_task_group_active)
* [`mark_task_ever_resolved`](#mark_task_ever_resolved)
* [`quarantine_queue_worker_with_last_date_active`](#quarantine_queue_worker_with_last_date_active)
* [`queue_artifact_present`](#queue_artifact_present)
* [`queue_worker_seen_with_last_date_active`](#queue_worker_seen_with_last_date_active)
* [`queue_worker_task_seen`](#queue_worker_task_seen)
* [`reclaim_task`](#reclaim_task)
* [`remove_task`](#remove_task)
* [`remove_task_dependency`](#remove_task_dependency)
* [`rerun_task`](#rerun_task)
* [`resolve_task`](#resolve_task)
* [`resolve_task_at_deadline`](#resolve_task_at_deadline)
* [`satisfy_task_dependency`](#satisfy_task_dependency)
* [`schedule_task`](#schedule_task)
* [`task_queue_seen`](#task_queue_seen)
* [`update_queue_artifact_2`](#update_queue_artifact_2)

### add_task_dependency

* *Mode*: write
* *Arguments*:
  * `dependent_task_id_in text`
  * `required_task_id_in text`
  * `requires_in task_requires`
  * `expires_in timestamptz`
* *Returns*: `void`
* *Last defined on version*: 49

Create an un-satisfied task dependency between the two tasks, with the given
requirement style and expiration. If the dependency already exists, nothing
happens.

### azure_queue_count

* *Mode*: read
* *Arguments*:
  * `queue_name text`
* *Returns*: `integer`
* *Last defined on version*: 6

Count non-expired messages in the named queue.


### azure_queue_delete

* *Mode*: write
* *Arguments*:
  * `queue_name text`
  * `message_id uuid`
  * `pop_receipt uuid`
* *Returns*: `void`
* *Last defined on version*: 3

Delete the message identified by the given `queue_name`, `message_id` and
`pop_receipt`.


### azure_queue_delete_expired

* *Mode*: write
* *Arguments*:
* *Returns*: `void`
* *Last defined on version*: 3

Delete all expired messages.  This is a maintenance task that should occur
about once an hour.


### azure_queue_get

* *Mode*: write
* *Arguments*:
  * `queue_name text`
  * `visible timestamp`
  * `count integer`
* *Returns*: `table`
  * `message_id uuid`
  * `message_text text`
  * `pop_receipt uuid`
* *Last defined on version*: 5

Get up to `count` messages from the given queue, setting the `visible`
column of each to the given value.  Returns a `message_id` and
`pop_receipt` for each one, for use with `azure_queue_delete` and
`azure_queue_update`.


### azure_queue_put

* *Mode*: write
* *Arguments*:
  * `queue_name text`
  * `message_text text`
  * `visible timestamp`
  * `expires timestamp`
* *Returns*: `void`
* *Last defined on version*: 3

Put the given message into the given queue.  The message will not be visible until
after the visible timestamp, and will disappear after the expires timestamp.


### azure_queue_update

* *Mode*: write
* *Arguments*:
  * `queue_name text`
  * `message_text text`
  * `message_id uuid`
  * `pop_receipt uuid`
  * `visible timestamp`
* *Returns*: `void`
* *Last defined on version*: 3

Update the message identified by the given `queue_name`, `message_id` and
`pop_receipt`, setting its `visible` and `message_text` properties as
given.


### cancel_task

* *Mode*: write
* *Arguments*:
  * `task_id text`
  * `reason text`
* *Returns*: `table`
  * `retries_left integer`
  * `runs jsonb`
  * `taken_until timestamptz`
* *Last defined on version*: 28

If the current run is pending or running, mark it as exception with the given
reason.  If the task is unscheduled, a run with that status is
created to represent the cancellation.  This returns the task's updated
status, or nothing if the current status was not as expected.

### check_task_claim

* *Mode*: write
* *Arguments*:
  * `task_id text`
  * `run_id int`
  * `taken_until_in timestamptz`
* *Returns*: `table`
  * `retries_left integer`
  * `runs jsonb`
  * `taken_until timestamptz`
* *Last defined on version*: 28

Check the given task for a claim on the given run expiring at the given
time.  If the run is still running, it is marked as claim-expired and
a retry scheduled (if retries_left).

This returns the task's updated status, or nothing if the current status
was not as expected.

### claim_task

* *Mode*: write
* *Arguments*:
  * `task_id text`
  * `run_id int`
  * `worker_group text`
  * `worker_id text`
  * `hint_id text`
  * `taken_until_in timestamptz`
* *Returns*: `table`
  * `retries_left integer`
  * `runs jsonb`
  * `taken_until timestamptz`
* *Last defined on version*: 28

Claim the given run of the given task for the given worker.  The hint is recorded in the run,
for comparison when the claim expires.  This returns the task's updated
status, or nothing if the current status was not as expected.

### create_queue_artifact

* *Mode*: write
* *Arguments*:
  * `task_id_in text`
  * `run_id_in integer`
  * `name_in text`
  * `storage_type_in text`
  * `content_type_in text`
  * `details_in jsonb`
  * `present_in boolean`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `task_id text`
  * `run_id integer`
  * `name text`
  * `storage_type text`
  * `content_type text`
  * `details jsonb`
  * `present boolean`
  * `expires timestamptz`
* *Last defined on version*: 24

Create a new artifact. Raises UNIQUE_VIOLATION if the artifact already exists.
Returns the newly created artifact.

### create_task_projid

* *Mode*: write
* *Arguments*:
  * `task_id text`
  * `task_queue_id text`
  * `scheduler_id text`
  * `project_id text`
  * `task_group_id text`
  * `dependencies jsonb`
  * `requires task_requires`
  * `routes jsonb`
  * `priority task_priority`
  * `retries integer`
  * `created timestamptz`
  * `deadline timestamptz`
  * `expires timestamptz`
  * `scopes jsonb`
  * `payload jsonb`
  * `metadata jsonb`
  * `tags jsonb`
  * `extra jsonb`
* *Returns*: `void`
* *Last defined on version*: 63

Create a new task, without scheduling it, and with empty values
for the status information.

### delete_queue_artifact

* *Mode*: write
* *Arguments*:
  * `task_id_in text`
  * `run_id_in integer`
  * `name_in text`
* *Returns*: `void`
* *Last defined on version*: 24

Delete a queue artifact.

### delete_queue_provisioner

* *Mode*: write
* *Arguments*:
  * `provisioner_id text`
  * `stability text`
  * `description text`
* *Returns*: `void`
* *Last defined on version*: 45

Delete a queue provisioner.

### delete_queue_worker_type

* *Mode*: write
* *Arguments*:
  * `provisioner_id text`
  * `worker_type text`
  * `stability text`
  * `description text`
* *Returns*: `void`
* *Last defined on version*: 44

Delete a queue worker type.

### ensure_task_group

* *Mode*: write
* *Arguments*:
  * `task_group_id_in text`
  * `scheduler_id_in text`
  * `expires_in timestamptz`
* *Returns*: `void`
* *Last defined on version*: 49

Ensure that the given task group exists, has the matching scheduler_id,
and has an expiration greater than the given expiration.  Expiration is
bumped by an hour at a time to avoid unnecessary updates.  This returns
23505 (UNIQUE_VIOLATION) when the group exists with a different
scheduler_id.

### expire_queue_workers

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`
* *Last defined on version*: 43

Expire non-quarantined queue workers that come before `expires_in`.
Returns a count of rows that have been deleted.

### expire_task_dependencies

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`
* *Last defined on version*: 28

Delete task dependencies with expiration dates before `expires_in`.
Returns a count of rows that have been deleted.

### expire_task_groups

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`
* *Last defined on version*: 28

Delete task groups with expiration dates before `expires_in`.
Returns a count of rows that have been deleted.

### expire_task_queues

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`
* *Last defined on version*: 53

Expire task queues that come before `expires_in`.
Returns a count of rows that have been deleted.

### expire_tasks

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`
* *Last defined on version*: 28

Delete tasks with expiration dates before `expires_in`.
Returns a count of rows that have been deleted.

### get_dependent_tasks

* *Mode*: read
* *Arguments*:
  * `required_task_id_in text`
  * `satisfied_in boolean`
  * `tasks_after_in text`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `dependent_task_id text`
  * `requires task_requires`
  * `satisfied boolean`
* *Last defined on version*: 46

Get the un-expired tasks that depend on this one, limiting to only (un)satisfied
dependencies if `satisfied_in` is not null.

Only dependencies with `dependent_task_id > tasks_after_in` are returned.
This supports paginated queries that are not susceptible to rows being
added or removed.  Typically only one of `page_offset_in` and
`tasks_after_in` are non-null.

### get_queue_artifact

* *Mode*: read
* *Arguments*:
  * `task_id_in text`
  * `run_id_in integer`
  * `name_in text`
* *Returns*: `table`
  * `task_id text`
  * `run_id integer`
  * `name text`
  * `storage_type text`
  * `content_type text`
  * `details jsonb`
  * `present boolean`
  * `expires timestamptz`
* *Last defined on version*: 24

Get a queue artifact. The returned table will have one or zero row.

### get_queue_artifacts_paginated

* *Mode*: read
* *Arguments*:
  * `task_id_in text`
  * `run_id_in integer`
  * `expires_in timestamptz`
  * `page_size_in integer`
  * `after_task_id_in text`
  * `after_run_id_in integer`
  * `after_name_in text`
* *Returns*: `table`
  * `task_id text`
  * `run_id integer`
  * `name text`
  * `storage_type text`
  * `content_type text`
  * `details jsonb`
  * `present boolean`
  * `expires timestamptz`
* *Last defined on version*: 69

Get existing queue artifacts, filtered by the optional arguments, ordered
by the `task_id`, `run_id`, and `name`.  The `after_*` arguments specify
where the page of results should begin, and must all be specified if any
are specified.  Typically these values would be drawn from the last item
in the previous page.

### get_task_group

* *Mode*: read
* *Arguments*:
  * `task_group_id_in text`
* *Returns*: `table`
  * `   task_group_id text`
  * `  scheduler_id text`
  * `  expires timestamptz `
* *Last defined on version*: 28

Get a task group.

### get_task_projid

* *Mode*: read
* *Arguments*:
  * `task_id_in text`
* *Returns*: `table`
  * `   task_id text`
  * `  task_queue_id text`
  * `  scheduler_id text`
  * `  project_id text`
  * `  task_group_id text`
  * `  dependencies jsonb`
  * `  requires task_requires`
  * `  routes jsonb`
  * `  priority task_priority`
  * `  retries integer`
  * `  retries_left int`
  * `  created timestamptz`
  * `  deadline timestamptz`
  * `  expires timestamptz`
  * `  scopes jsonb`
  * `  payload jsonb`
  * `  metadata jsonb`
  * `  tags jsonb`
  * `  extra jsonb`
  * `  runs jsonb`
  * `  taken_until timestamptz `
* *Last defined on version*: 63

Get all properties of a task.  Note that all properties but `runs`,
`retries_left`, and `taken_until` are immutable.

### get_task_queue

* *Mode*: read
* *Arguments*:
  * `task_queue_id_in text`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `task_queue_id text`
  * `expires timestamptz`
  * `last_date_active timestamptz`
  * `description text`
  * `stability text`
  * `etag uuid`
* *Last defined on version*: 53

Get a non-expired task queue by task_queue_id.

### get_task_queues

* *Mode*: read
* *Arguments*:
  * `task_queue_id_in text`
  * `expires_in timestamptz`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `task_queue_id text`
  * `expires timestamptz`
  * `last_date_active timestamptz`
  * `description text`
  * `stability text`
  * `etag uuid`
* *Last defined on version*: 53

Get task queues ordered by `task_queue_id`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### get_tasks_by_task_group_projid

* *Mode*: read
* *Arguments*:
  * `task_group_id_in text`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `   task_id text`
  * `  task_queue_id text`
  * `  scheduler_id text`
  * `  project_id text`
  * `  task_group_id text`
  * `  dependencies jsonb`
  * `  requires task_requires`
  * `  routes jsonb`
  * `  priority task_priority`
  * `  retries integer`
  * `  retries_left int`
  * `  created timestamptz`
  * `  deadline timestamptz`
  * `  expires timestamptz`
  * `  scopes jsonb`
  * `  payload jsonb`
  * `  metadata jsonb`
  * `  tags jsonb`
  * `  extra jsonb`
  * `  runs jsonb`
  * `  taken_until timestamptz `
* *Last defined on version*: 63

Get all properties of all tasks in the given task group.

### is_task_blocked

* *Mode*: read
* *Arguments*:
  * `dependent_task_id_in text`
* *Returns*: `boolean`
* *Last defined on version*: 28

Return true if the task has remaining un-satisfied dependencies.

### is_task_group_active

* *Mode*: read
* *Arguments*:
  * `task_group_id_in text`
* *Returns*: `boolean`
* *Last defined on version*: 28

temp, removed in next commit

### mark_task_ever_resolved

* *Mode*: write
* *Arguments*:
  * `task_id_in text`
* *Returns*: `void`
* *Last defined on version*: 28

temp, removed in next commit

### quarantine_queue_worker_with_last_date_active

* *Mode*: write
* *Arguments*:
  * `task_queue_id_in text`
  * `worker_group_in text`
  * `worker_id_in text`
  * `quarantine_until_in timestamptz`
* *Returns*: `table`
  * `task_queue_id text`
  * `worker_group text`
  * `worker_id text`
  * `quarantine_until timestamptz`
  * `expires timestamptz`
  * `first_claim timestamptz`
  * `recent_tasks jsonb`
  * `last_date_active timestamptz`
* *Last defined on version*: 72

Update the quarantine_until date for a worker.  The Queue service interprets a date in the past
as "not quarantined".  This function also "bumps" the expiration of the worker so that un-quarantined
workers do not immediately expire.  Returns the worker row just as get_queue_worker would, or no rows if
no such worker exists.

### queue_artifact_present

* *Mode*: write
* *Arguments*:
  * `task_id_in text`
  * `run_id_in integer`
  * `name_in text`
* *Returns*: `table`
  * `task_id text`
  * `run_id integer`
  * `name text`
  * `storage_type text`
  * `content_type text`
  * `details jsonb`
  * `present boolean`
  * `expires timestamptz`
* *Last defined on version*: 68

Mark the given queue artifact as present, returning the updated artifact.  Returns
nothing if no such artifact exists.

### queue_worker_seen_with_last_date_active

* *Mode*: write
* *Arguments*:
  * `task_queue_id_in text`
  * `worker_group_in text`
  * `worker_id_in text`
  * `expires_in timestamptz`
* *Returns*: `void`
* *Last defined on version*: 72

Recognize that a worker has been seen by the queue, creating it if necessary.  This is called
when workers claim or re-claim work.  The expiration time is not allowed to move backward.
Will also always bump its last date active time.

This function always writes to the DB, so calls should be suitably rate-limited at the
client side.

### queue_worker_task_seen

* *Mode*: write
* *Arguments*:
  * `task_queue_id_in text`
  * `worker_group_in text`
  * `worker_id_in text`
  * `task_run_in jsonb`
* *Returns*: `void`
* *Last defined on version*: 64

Update the worker record to indicate that this task run was seen there.  The
task run should be a JSON object with keys `taskId` and `runId`.  This will
add the task to `recent_tasks`, keeping the most recent 20 tasks. This
will do nothing, but not fail, if the worker does not exist, as it is
unusual for a nonexistent worker to claim work.

### reclaim_task

* *Mode*: write
* *Arguments*:
  * `task_id text`
  * `run_id int`
  * `taken_until_in timestamptz`
* *Returns*: `table`
  * `retries_left integer`
  * `runs jsonb`
  * `taken_until timestamptz`
* *Last defined on version*: 28

Relaim the given run of the given task run, until the new taken_until time.
This returns the task's updated status, or nothing if the current status was not as expected.

### remove_task

* *Mode*: write
* *Arguments*:
  * `task_id text`
* *Returns*: `void`
* *Last defined on version*: 28

Remove the given task, regardless of its expiration status.  This is
typically used when task creation has failed.

### remove_task_dependency

* *Mode*: write
* *Arguments*:
  * `dependent_task_id_in text`
  * `required_task_id_in text`
* *Returns*: `void`
* *Last defined on version*: 28

Mark the given dependency as satisfied.  If the dependency does not exist, nothing
happens.

### rerun_task

* *Mode*: write
* *Arguments*:
  * `task_id text`
* *Returns*: `table`
  * `retries_left integer`
  * `runs jsonb`
  * `taken_until timestamptz`
* *Last defined on version*: 28

Ensure that no run is currently running or pending, and then create a new
pending run with the given reason.  This also resets the retries_left
column to `retries` (unless the sanity-check maximum runs has been
reached).  This returns the task's updated status, or nothing if the
current status was not as expected.

### resolve_task

* *Mode*: write
* *Arguments*:
  * `task_id text`
  * `run_id int`
  * `state text`
  * `reason text`
  * `retry_reason text`
* *Returns*: `table`
  * `retries_left integer`
  * `runs jsonb`
  * `taken_until timestamptz`
* *Last defined on version*: 28

Resolve the given run with the given state and reason, setting
run.resolved and resetting `taken_until`.  If `retry_reason` is not null
and there are `retries_left`, a new pending run is added, and
`retries_left` is decremented.  This returns the task's updated status,
or nothing if the current status was not as expected.

### resolve_task_at_deadline

* *Mode*: write
* *Arguments*:
  * `task_id text`
* *Returns*: `table`
  * `retries_left integer`
  * `runs jsonb`
  * `taken_until timestamptz`
* *Last defined on version*: 28

The given task has reached its deadline, so mark it as resolved, adding a
run if necessary.  This returns the task's updated status, or nothing if
the current status was not as expected.

### satisfy_task_dependency

* *Mode*: write
* *Arguments*:
  * `dependent_task_id_in text`
  * `required_task_id_in text`
* *Returns*: `void`
* *Last defined on version*: 28

Mark the given dependency as satisfied.  If the dependency does not exist, nothing
happens.

### schedule_task

* *Mode*: write
* *Arguments*:
  * `task_id text`
  * `reason_created text`
* *Returns*: `table`
  * `retries_left integer`
  * `runs jsonb`
  * `taken_until timestamptz`
* *Last defined on version*: 28

Schedule the initial run for a task, moving the task from "unscheduled" to "pending".
This returns the task's updated status, or nothing if the current status was not
as expected.

### task_queue_seen

* *Mode*: write
* *Arguments*:
  * `task_queue_id_in text`
  * `expires_in timestamptz`
  * `description_in text`
  * `stability_in text`
* *Returns*: `void`
* *Last defined on version*: 64

Recognize that a task queue has been seen, creating it if necessary, updating
its properties if not null, and in any case bumping its last seen time time.
The expiration time is not allowed to move backward.

This function always writes to the DB, so calls should be suitably rate-limited at the
client side.

### update_queue_artifact_2

* *Mode*: write
* *Arguments*:
  * `task_id_in text`
  * `run_id_in integer`
  * `name_in text`
  * `storage_type_in text`
  * `details_in jsonb`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `task_id text`
  * `run_id integer`
  * `name text`
  * `storage_type text`
  * `content_type text`
  * `details jsonb`
  * `present boolean`
  * `expires timestamptz`
* *Last defined on version*: 62

Update a queue artifact, including its storageType.
Returns the up-to-date artifact row that have the same task id, run id, and name.

### deprecated methods

* `get_queue_worker_tqid(task_queue_id_in text, worker_group_in text, worker_id_in text, expires_in timestamptz)` (compatibility guaranteed until v46.0.0)
* `get_queue_worker_tqid_with_last_date_active(task_queue_id_in text, worker_group_in text, worker_id_in text, expires_in timestamptz)` (compatibility guaranteed until v46.0.0)
* `get_queue_workers_tqid(task_queue_id_in text, expires_in timestamptz, page_size_in integer, page_offset_in integer)` (compatibility guaranteed until v46.0.0)
* `get_queue_workers_tqid_with_last_date_active(task_queue_id_in text, expires_in timestamptz, page_size_in integer, page_offset_in integer)` (compatibility guaranteed until v46.0.0)
* `quarantine_queue_worker(task_queue_id_in text, worker_group_in text, worker_id_in text, quarantine_until_in timestamptz)` (compatibility guaranteed until v46.0.0)
* `queue_worker_seen(task_queue_id_in text, worker_group_in text, worker_id_in text, expires_in timestamptz)` (compatibility guaranteed until v46.0.0)

## secrets

* [`delete_secret`](#delete_secret)
* [`expire_secrets`](#expire_secrets)
* [`get_secret`](#get_secret)
* [`get_secrets`](#get_secrets)
* [`upsert_secret`](#upsert_secret)

### delete_secret

* *Mode*: write
* *Arguments*:
  * `name_in text`
* *Returns*: `void`
* *Last defined on version*: 42

Delete a secret entirely

### expire_secrets

* *Mode*: write
* *Arguments*:
* *Returns*: `integer`
* *Last defined on version*: 42

Delete all secrets with an 'expires' in the past.

### get_secret

* *Mode*: read
* *Arguments*:
  * `name_in text`
* *Returns*: `table`
  * `name text`
  * `encrypted_secret jsonb`
  * `expires timestamptz`
* *Last defined on version*: 42

Get a single secret (including secret content and expiration)

### get_secrets

* *Mode*: read
* *Arguments*:
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `name text`
* *Last defined on version*: 42

Get many secrets at once. This only includes names.
Fetch an individual secret to get the contents

### upsert_secret

* *Mode*: write
* *Arguments*:
  * `name_in text`
  * `encrypted_secret_in jsonb`
  * `expires_in timestamptz`
* *Returns*: `void`
* *Last defined on version*: 42

Store an encrypted secret whether it is new or being updated

## web_server

* [`add_github_access_token`](#add_github_access_token)
* [`create_access_token`](#create_access_token)
* [`create_authorization_code`](#create_authorization_code)
* [`expire_access_tokens`](#expire_access_tokens)
* [`expire_authorization_codes`](#expire_authorization_codes)
* [`expire_sessions`](#expire_sessions)
* [`get_access_token`](#get_access_token)
* [`get_authorization_code`](#get_authorization_code)
* [`load_github_access_token`](#load_github_access_token)
* [`session_add`](#session_add)
* [`session_load`](#session_load)
* [`session_remove`](#session_remove)
* [`session_touch`](#session_touch)

### add_github_access_token

* *Mode*: write
* *Arguments*:
  * `user_id_in text`
  * `encrypted_access_token_in jsonb`
* *Returns*: `void`
* *Last defined on version*: 27

Sets the encrypted access token for `user_id_in` to
`encrypted_access_token_in`.

If no access token is currently set for `user_id_in`, a new row is
inserted, otherwise the existing row's encrypted access token is updated
to `encrypted_access_token_in`.

### create_access_token

* *Mode*: write
* *Arguments*:
  * `hashed_access_token_in text`
  * `encrypted_access_token_in jsonb`
  * `client_id_in text`
  * `redirect_uri_in text`
  * `identity_in text`
  * `identity_provider_id_in text`
  * `expires_in timestamptz`
  * `client_details_in jsonb`
* *Returns*: `table`
  * `hashed_access_token text`
  * `encrypted_access_token jsonb`
  * `client_id text`
  * `redirect_uri text`
  * `identity text`
  * `identity_provider_id text`
  * `expires timestamptz`
  * `client_details jsonb`
* *Last defined on version*: 40

Create an access token entry.

### create_authorization_code

* *Mode*: write
* *Arguments*:
  * `code_in text`
  * `client_id_in text`
  * `redirect_uri_in text`
  * `identity_in text`
  * `identity_provider_id_in text`
  * `expires_in timestamptz`
  * `client_details_in jsonb`
* *Returns*: `table`
  * `code text`
  * `client_id text`
  * `redirect_uri text`
  * `identity text`
  * `identity_provider_id text`
  * `expires timestamptz`
  * `client_details jsonb`
* *Last defined on version*: 39

Create an authorization code.

### expire_access_tokens

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`
* *Last defined on version*: 40

Delete access token entries that expireq before the current time.
Returns a count of rows that have been deleted.

### expire_authorization_codes

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`
* *Last defined on version*: 39

Delete authorization codes that expire before `expires_in`.
Returns a count of rows that have been deleted.

### expire_sessions

* *Mode*: write
* *Arguments*:
* *Returns*: `integer`
* *Last defined on version*: 38

Delete sessions that expire before the current time.
Returns a count of rows that have been deleted.

### get_access_token

* *Mode*: read
* *Arguments*:
  * `hashed_access_token_in text`
* *Returns*: `table`
  * `hashed_access_token text`
  * `encrypted_access_token jsonb`
  * `client_id text`
  * `redirect_uri text`
  * `identity text`
  * `identity_provider_id text`
  * `expires timestamptz`
  * `client_details jsonb`
* *Last defined on version*: 40

Get an access token entry.

### get_authorization_code

* *Mode*: read
* *Arguments*:
  * `code_in text`
* *Returns*: `table`
  * `code text`
  * `client_id text`
  * `redirect_uri text`
  * `identity text`
  * `identity_provider_id text`
  * `expires timestamptz`
  * `client_details jsonb`
* *Last defined on version*: 39

Get an authorization code entry given a code.

### load_github_access_token

* *Mode*: read
* *Arguments*:
  * `user_id_in text`
* *Returns*: `table`
  * `encrypted_access_token jsonb`
* *Last defined on version*: 27

Returns the encrypted github access token for a given user.

### session_add

* *Mode*: write
* *Arguments*:
  * `hashed_session_id_in text`
  * `encrypted_session_id_in jsonb`
  * `data_in jsonb`
  * `expires_in timestamptz`
* *Returns*: `void`
* *Last defined on version*: 38

Set a session.

If no session exists with hashed session id `hashed_session_id_in`,
a new row is inserted, otherwise the existing session's data is replaced
with the data in `data_in`.

### session_load

* *Mode*: read
* *Arguments*:
  * `hashed_session_id_in text`
* *Returns*: `table`
  * `hashed_session_id text`
  * `encrypted_session_id jsonb`
  * `data jsonb`
  * `expires timestamptz`
* *Last defined on version*: 38

Returns the session for a given hashed session id.

### session_remove

* *Mode*: write
* *Arguments*:
  * `hashed_session_id_in text`
* *Returns*: `void`
* *Last defined on version*: 38

Removes a web session

### session_touch

* *Mode*: write
* *Arguments*:
  * `hashed_session_id_in text`
  * `data_in jsonb`
  * `expires_in timestamptz`
* *Returns*: `void`
* *Last defined on version*: 38

Touch a given session given a hashed session id and session `data`.
If the hashed session id does not exist, then an error code `P0002` will be thrown.

## worker_manager

* [`create_worker`](#create_worker)
* [`create_worker_pool`](#create_worker_pool)
* [`create_worker_pool_error`](#create_worker_pool_error)
* [`delete_worker`](#delete_worker)
* [`delete_worker_pool`](#delete_worker_pool)
* [`delete_worker_pool_error`](#delete_worker_pool_error)
* [`expire_worker_pool_errors`](#expire_worker_pool_errors)
* [`expire_worker_pools`](#expire_worker_pools)
* [`expire_workers`](#expire_workers)
* [`get_non_stopped_workers_quntil_providers`](#get_non_stopped_workers_quntil_providers)
* [`get_queue_worker_with_wm_join`](#get_queue_worker_with_wm_join)
* [`get_queue_workers_with_wm_join`](#get_queue_workers_with_wm_join)
* [`get_task_queue_wm_2`](#get_task_queue_wm_2)
* [`get_task_queues_wm`](#get_task_queues_wm)
* [`get_worker_2`](#get_worker_2)
* [`get_worker_pool_error`](#get_worker_pool_error)
* [`get_worker_pool_errors_for_worker_pool`](#get_worker_pool_errors_for_worker_pool)
* [`get_worker_pool_with_capacity_and_counts_by_state`](#get_worker_pool_with_capacity_and_counts_by_state)
* [`get_worker_pools_with_capacity_and_counts_by_state`](#get_worker_pools_with_capacity_and_counts_by_state)
* [`get_workers_without_provider_data`](#get_workers_without_provider_data)
* [`remove_worker_pool_previous_provider_id`](#remove_worker_pool_previous_provider_id)
* [`update_worker_2`](#update_worker_2)
* [`update_worker_pool_provider_data`](#update_worker_pool_provider_data)
* [`update_worker_pool_with_capacity_and_counts_by_state`](#update_worker_pool_with_capacity_and_counts_by_state)

### create_worker

* *Mode*: write
* *Arguments*:
  * `worker_pool_id_in text`
  * `worker_group_in text`
  * `worker_id_in text`
  * `provider_id_in text`
  * `created_in timestamptz`
  * `expires_in timestamptz`
  * `state_in text`
  * `provider_data_in jsonb`
  * `capacity_in integer`
  * `last_modified_in timestamptz`
  * `last_checked_in timestamptz`
* *Returns*: `uuid`
* *Last defined on version*: 12

Create a new worker. Raises UNIQUE_VIOLATION if the worker already exists.
Returns the etag of the newly created worker.

### create_worker_pool

* *Mode*: write
* *Arguments*:
  * `worker_pool_id_in text`
  * `provider_id_in text`
  * `previous_provider_ids_in jsonb`
  * `description_in text`
  * `config_in jsonb`
  * `created_in timestamptz`
  * `last_modified_in timestamptz`
  * `owner_in text`
  * `email_on_error_in boolean`
  * `provider_data_in jsonb`
* *Returns*: `void`
* *Last defined on version*: 10

Create a new worker pool.  Raises UNIQUE_VIOLATION if the pool already exists.

### create_worker_pool_error

* *Mode*: write
* *Arguments*:
  * `error_id_in text`
  * `worker_pool_id_in text`
  * `reported_in timestamptz`
  * `kind_in text`
  * `title_in text`
  * `description_in text`
  * `extra_in jsonb`
* *Returns*: `uuid`
* *Last defined on version*: 29

Create a new worker pool error.  Raises UNIQUE_VIOLATION if the error already exists.

### delete_worker

* *Mode*: write
* *Arguments*:
  * `worker_pool_id_in text`
  * `worker_group_in text`
  * `worker_id_in text`
* *Returns*: `void`
* *Last defined on version*: 12

Delete a worker.

### delete_worker_pool

* *Mode*: write
* *Arguments*:
  * `worker_pool_id_in text`
* *Returns*: `void`
* *Last defined on version*: 10

Delete a worker pool immediately.

### delete_worker_pool_error

* *Mode*: write
* *Arguments*:
  * `error_id_in text`
  * `worker_pool_id_in text`
* *Returns*: `void`
* *Last defined on version*: 29

Delete a worker pool error immediately.

### expire_worker_pool_errors

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`
* *Last defined on version*: 29

Expire worker pool errors reported before `expires_in`.
Returns a count of rows that have been deleted.

### expire_worker_pools

* *Mode*: write
* *Arguments*:
* *Returns*: `table`
  * `worker_pool_id text`
* *Last defined on version*: 10

Expire worker pools, deleting those which have provider-id null-provider and
no previous_provider_ids.  Returns the worker pool ids that it deletes.

### expire_workers

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`
* *Last defined on version*: 12

Expire workers that come before `expires_in`.
Returns a count of rows that have been deleted.

### get_non_stopped_workers_quntil_providers

* *Mode*: read
* *Arguments*:
  * `worker_pool_id_in text`
  * `worker_group_in text`
  * `worker_id_in text`
  * `providers_filter_cond text`
  * `providers_filter_value text`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `worker_pool_id text`
  * `worker_group text`
  * `worker_id text`
  * `provider_id text`
  * `created timestamptz`
  * `expires timestamptz`
  * `state text`
  * `provider_data jsonb`
  * `capacity integer`
  * `last_modified timestamptz`
  * `last_checked timestamptz`
  * `secret jsonb`
  * `etag uuid`
  * `quarantine_until timestamptz`
* *Last defined on version*: 71

Get non-stopped workers filtered by the optional arguments,
ordered by `worker_pool_id`, `worker_group`, and  `worker_id`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset `page_offset`.
The `quaratine_until` contains NULL or a date in the past if the
worker is not quarantined, otherwise the date until which it is
quaratined. `providers_filter_cond` and `providers_filter_value` used to
filter `=` or `<>` provider by value.

### get_queue_worker_with_wm_join

* *Mode*: read
* *Arguments*:
  * `task_queue_id_in text`
  * `worker_group_in text`
  * `worker_id_in text`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `worker_pool_id text`
  * `worker_group text`
  * `worker_id text`
  * `quarantine_until timestamptz`
  * `expires timestamptz`
  * `first_claim timestamptz`
  * `recent_tasks jsonb`
  * `last_date_active timestamptz`
  * `state text`
  * `capacity int4`
  * `provider_id text`
  * `etag uuid`
* *Last defined on version*: 73

Get a non-expired queue worker by worker_pool_id, worker_group, and worker_id.
Workers are not considered expired until after their quarantine date expires.
This also performs an outer join with the worker_manager.worker table for more data.

### get_queue_workers_with_wm_join

* *Mode*: read
* *Arguments*:
  * `task_queue_id_in text`
  * `expires_in timestamptz`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `worker_pool_id text`
  * `worker_group text`
  * `worker_id text`
  * `quarantine_until timestamptz`
  * `expires timestamptz`
  * `first_claim timestamptz`
  * `recent_tasks jsonb`
  * `last_date_active timestamptz`
  * `state text`
  * `capacity int4`
  * `provider_id text`
  * `etag uuid`
* *Last defined on version*: 73

Get non-expired queue workers ordered by worker_pool_id, worker_group, and worker_id.
Workers are not considered expired until after their quarantine date expires.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.
This also performs an outer join with the worker_manager.worker table for more data.

### get_task_queue_wm_2

* *Mode*: read
* *Arguments*:
  * `task_queue_id_in text`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `task_queue_id text`
  * `expires timestamptz`
  * `last_date_active timestamptz`
  * `description text`
  * `stability text`
  * `etag uuid`
* *Last defined on version*: 75

Get a non-expired task queue by task_queue_id.

### get_task_queues_wm

* *Mode*: read
* *Arguments*:
  * `task_queue_id_in text`
  * `expires_in timestamptz`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `task_queue_id text`
  * `expires timestamptz`
  * `last_date_active timestamptz`
  * `description text`
  * `stability text`
  * `etag uuid`
* *Last defined on version*: 74

Get task queues ordered by `task_queue_id`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### get_worker_2

* *Mode*: read
* *Arguments*:
  * `worker_pool_id_in text`
  * `worker_group_in text`
  * `worker_id_in text`
* *Returns*: `table`
  * `worker_pool_id text`
  * `worker_group text`
  * `worker_id text`
  * `provider_id text`
  * `created timestamptz`
  * `expires timestamptz`
  * `state text`
  * `provider_data jsonb`
  * `capacity integer`
  * `last_modified timestamptz`
  * `last_checked timestamptz`
  * `secret jsonb`
  * `etag uuid`
* *Last defined on version*: 14

Get an existing worker. The returned table will have one or (if no such worker is defined) zero rows.

### get_worker_pool_error

* *Mode*: read
* *Arguments*:
  * `error_id_in text`
  * `worker_pool_id_in text`
* *Returns*: `table`
  * `error_id text`
  * `worker_pool_id text`
  * `reported timestamptz`
  * `kind text`
  * `title text`
  * `description text`
  * `extra jsonb`
* *Last defined on version*: 29

Get an existing worker pool error.  The returned table will have one or (if no such worker pool error is defined) zero rows.

### get_worker_pool_errors_for_worker_pool

* *Mode*: read
* *Arguments*:
  * `error_id_in text`
  * `worker_pool_id_in text`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `error_id text`
  * `worker_pool_id text`
  * `reported timestamptz`
  * `kind text`
  * `title text`
  * `description text`
  * `extra jsonb`
* *Last defined on version*: 31

Get existing worker pool errors filtered by `worker_pool_id` and `error_id`,
ordered by `reported`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### get_worker_pool_with_capacity_and_counts_by_state

* *Mode*: read
* *Arguments*:
  * `worker_pool_id_in text`
* *Returns*: `table`
  * `worker_pool_id text`
  * `provider_id text`
  * `previous_provider_ids jsonb`
  * `description text`
  * `config jsonb`
  * `created timestamptz`
  * `last_modified timestamptz`
  * `owner text`
  * `email_on_error boolean`
  * `provider_data jsonb`
  * `current_capacity integer`
  * `requested_count integer`
  * `running_count integer`
  * `stopping_count integer`
  * `stopped_count integer`
  * `requested_capacity integer`
  * `running_capacity integer`
  * `stopping_capacity integer`
  * `stopped_capacity integer`
* *Last defined on version*: 70

Get an existing worker pool.  The returned table will have one or (if no such worker pool is defined) zero rows.

### get_worker_pools_with_capacity_and_counts_by_state

* *Mode*: read
* *Arguments*:
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `worker_pool_id text`
  * `provider_id text`
  * `previous_provider_ids jsonb`
  * `description text`
  * `config jsonb`
  * `created timestamptz`
  * `last_modified timestamptz`
  * `owner text`
  * `email_on_error boolean`
  * `provider_data jsonb`
  * `current_capacity integer`
  * `requested_count integer`
  * `running_count integer`
  * `stopping_count integer`
  * `stopped_count integer`
  * `requested_capacity integer`
  * `running_capacity integer`
  * `stopping_capacity integer`
  * `stopped_capacity integer`
* *Last defined on version*: 70

Get existing worker pools, ordered by `worker_pool_id`.  If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### get_workers_without_provider_data

* *Mode*: read
* *Arguments*:
  * `worker_pool_id_in text`
  * `worker_group_in text`
  * `worker_id_in text`
  * `state_in text`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `worker_pool_id text`
  * `worker_group text`
  * `worker_id text`
  * `provider_id text`
  * `created timestamptz`
  * `expires timestamptz`
  * `state text`
  * `capacity integer`
  * `last_modified timestamptz`
  * `last_checked timestamptz`
* *Last defined on version*: 48

Get existing workers (without their `provider_data`) filtered by the optional arguments,
ordered by `worker_pool_id`, `worker_group`, and  `worker_id`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### remove_worker_pool_previous_provider_id

* *Mode*: write
* *Arguments*:
  * `worker_pool_id_in text`
  * `provider_id_in text`
* *Returns*: `void`
* *Last defined on version*: 10

Remove the given provider_id from the worker pool's previous_provider_ids.  It is
not an error if the worker pool does not exist, or if the provider_id is not in the
previous_provider_ids set.

### update_worker_2

* *Mode*: write
* *Arguments*:
  * `worker_pool_id_in text`
  * `worker_group_in text`
  * `worker_id_in text`
  * `provider_id_in text`
  * `created_in timestamptz`
  * `expires_in timestamptz`
  * `state_in text`
  * `provider_data_in jsonb`
  * `capacity_in integer`
  * `last_modified_in timestamptz`
  * `last_checked_in timestamptz`
  * `etag_in uuid`
  * `secret_in jsonb`
* *Returns*: `table`
  * `worker_pool_id text`
  * `worker_group text`
  * `worker_id text`
  * `provider_id text`
  * `created timestamptz`
  * `expires timestamptz`
  * `state text`
  * `provider_data jsonb`
  * `capacity integer`
  * `last_modified timestamptz`
  * `last_checked timestamptz`
  * `etag uuid`
  * `secret jsonb`
* *Last defined on version*: 14

Update a worker.
Returns the up-to-date worker row that have the same worker_pool_id, worker_group, and worker_id.
If the etag argument is empty then the update will overwrite the matched row.
Else, the function will fail if the etag is out of date. This is useful for concurency handling.

### update_worker_pool_provider_data

* *Mode*: write
* *Arguments*:
  * `worker_pool_id_in text`
  * `provider_id_in text`
  * `provider_data_in jsonb`
* *Returns*: `void`
* *Last defined on version*: 10

Update the provider_data for the given provider_id in this worker pool.  Note that
this sets the provider_data property unconditionally, and it is up to the service
to ensure that concurrent modifications do not occur.  It is not an error if the
worker pool does not exist.

### update_worker_pool_with_capacity_and_counts_by_state

* *Mode*: write
* *Arguments*:
  * `worker_pool_id_in text`
  * `provider_id_in text`
  * `description_in text`
  * `config_in jsonb`
  * `last_modified_in timestamptz`
  * `owner_in text`
  * `email_on_error_in boolean`
* *Returns*: `table`
  * `worker_pool_id text`
  * `provider_id text`
  * `description text`
  * `config jsonb`
  * `created timestamptz`
  * `last_modified timestamptz`
  * `owner text`
  * `email_on_error boolean`
  * `previous_provider_id text`
  * `current_capacity integer`
  * `requested_count integer`
  * `running_count integer`
  * `stopping_count integer`
  * `stopped_count integer`
  * `requested_capacity integer`
  * `running_capacity integer`
  * `stopping_capacity integer`
  * `stopped_capacity integer`
* *Last defined on version*: 70

Update API-accessible columns on an existig worker pool.  All fields are
overridden, but if the provider_id changes, then the existing provider_id
is added to previous_provider_ids.  The return value contains values
required for an API response and previous_provider_id (singular) containing
the provider_id found before the update.  If no such worker pool exists,
the return value is an empty set.

### deprecated methods

* `get_non_stopped_workers_quntil(worker_pool_id_in text, worker_group_in text, worker_id_in text, page_size_in integer, page_offset_in integer)` (compatibility guaranteed until v46.0.0)
* `get_task_queue_wm(task_queue_id_in text, expires_in timestamptz, page_size_in integer, page_offset_in integer)` (compatibility guaranteed until v46.0.0)
* `get_worker_pool_with_capacity(worker_pool_id_in text)` (compatibility guaranteed until v46.0.0)
* `get_worker_pools_with_capacity(page_size_in integer, page_offset_in integer)` (compatibility guaranteed until v46.0.0)
* `update_worker_pool_with_capacity(worker_pool_id_in text, provider_id_in text, description_in text, config_in jsonb, last_modified_in timestamptz, owner_in text, email_on_error_in boolean)` (compatibility guaranteed until v46.0.0)
