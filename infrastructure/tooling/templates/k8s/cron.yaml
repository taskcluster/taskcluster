apiVersion: batch/v1
kind: CronJob
metadata:
  name: ${projectName}-${lowercase(procName)}
  labels: {$eval: labels}
spec:
  # TC crontasks assume they are not running concurrently
  concurrencyPolicy: Forbid
  schedule: ${schedule}
  jobTemplate:
    metadata:
      labels: {$eval: labels}
    spec:
      # terminate the job one minute before the next job begins, so that a
      # hung or long-running job is recycled at every scheduled interval
      activeDeadlineSeconds: {$eval: 'deadlineSeconds - 60'}
      template:
        metadata:
          labels: {$eval: labels}
        spec:
          # On failure, run the pod again; this lets us run the task even in
          # the face of k8s node failure, with the concurrencyPolicy ensuring
          # that two pods never run in parallel.
          restartPolicy: OnFailure
          imagePullSecrets: IMAGE_PULL_SECRETS_STRING
          securityContext:
            runAsNonRoot: true
          containers:
          - name: ${projectName}-${lowercase(procName)}
            image: '{{ .Values.dockerImage }}'
            imagePullPolicy: Always
            args: ['${serviceName}/${procName}']
            securityContext:
              allowPrivilegeEscalation: false
            resources:
              requests:
                cpu: '{{ .Values.${configName}.procs.${configProcName}.cpu }}'
                memory: '{{ .Values.${configName}.procs.${configProcName}.memory }}'
            env:
              - name: TASKCLUSTER_ROOT_URL
                value: '{{ .Values.rootUrl }}'
              - name: USE_KUBERNETES_DNS_SERVICE_DISCOVERY
                value: '{{ .Values.useKubernetesDnsServiceDiscovery }}'
              - name: NODE_ENV
                value: 'production'
            envFrom:
              - secretRef:
                  name: ${projectName}
              - configMapRef:
                  name: ${projectName}
