// This source code file is AUTO-GENERATED by github.com/taskcluster/jsonschema2go

package tcqueue

import (
	"encoding/json"
	"errors"

	tcclient "github.com/taskcluster/taskcluster/clients/client-go/v14"
)

type (
	// Actions provide a generic mechanism to expose additional features of a
	// provisioner, worker type, or worker to Taskcluster clients.
	//
	// An action is comprised of metadata describing the feature it exposes,
	// together with a webhook for triggering it.
	//
	// The Taskcluster tools site, for example, retrieves actions when displaying
	// provisioners, worker types and workers. It presents the provisioner/worker
	// type/worker specific actions to the user. When the user triggers an action,
	// the web client takes the registered webhook, substitutes parameters into the
	// URL (see `url`), signs the requests with the Taskcluster credentials of the
	// user operating the web interface, and issues the HTTP request.
	//
	// The level to which the action relates (provisioner, worker type, worker) is
	// called the action context. All actions, regardless of the action contexts,
	// are registered against the provisioner when calling
	// `queue.declareProvisioner`.
	//
	// The action context is used by the web client to determine where in the web
	// interface to present the action to the user as follows:
	//
	// | `context`   | Tool where action is displayed |
	// |-------------|--------------------------------|
	// | provisioner | Provisioner Explorer           |
	// | worker-type | Workers Explorer               |
	// | worker      | Worker Explorer                |
	//
	// See [actions docs](/docs/reference/platform/taskcluster-queue/docs/actions)
	// for more information.
	Action struct {

		// Actions have a "context" that is one of provisioner, worker-type, or worker, indicating
		// which it applies to. `context` is used by the front-end to know where to display the action.
		//
		// | `context`   | Page displayed        |
		// |-------------|-----------------------|
		// | provisioner | Provisioner Explorer  |
		// | worker-type | Workers Explorer      |
		// | worker      | Worker Explorer       |
		//
		// Possible values:
		//   * "provisioner"
		//   * "worker-type"
		//   * "worker"
		Context string `json:"context"`

		// Description of the provisioner.
		Description string `json:"description"`

		// Method to indicate the desired action to be performed for a given resource.
		//
		// Possible values:
		//   * "POST"
		//   * "PUT"
		//   * "DELETE"
		//   * "PATCH"
		Method string `json:"method"`

		// Short names for things like logging/error messages.
		Name string `json:"name"`

		// Appropriate title for any sort of Modal prompt.
		Title json.RawMessage `json:"title"`

		// When an action is triggered, a request is made using the `url` and `method`.
		// Depending on the `context`, the following parameters will be substituted in the url:
		//
		// | `context`   | Path parameters                                          |
		// |-------------|----------------------------------------------------------|
		// | provisioner | <provisionerId>                                          |
		// | worker-type | <provisionerId>, <workerType>                            |
		// | worker      | <provisionerId>, <workerType>, <workerGroup>, <workerId> |
		//
		// _Note: The request needs to be signed with the user's Taskcluster credentials._
		URL string `json:"url"`
	}

	// Information about an artifact for the given `taskId` and `runId`.
	Artifact struct {

		// Mimetype for the artifact that was created.
		//
		// Max length: 255
		ContentType string `json:"contentType"`

		// Date and time after which the artifact created will be automatically
		// deleted by the queue.
		Expires tcclient.Time `json:"expires"`

		// Name of the artifact that was created, this is useful if you want to
		// attempt to fetch the artifact.
		//
		// Max length: 1024
		Name string `json:"name"`

		// This is the `storageType` for the request that was used to create
		// the artifact.
		//
		// Possible values:
		//   * "blob"
		//   * "s3"
		//   * "azure"
		//   * "reference"
		//   * "error"
		StorageType string `json:"storageType"`
	}

	// Request for an Azure Shared Access Signature (SAS) that will allow
	// you to upload an artifact to an Azure blob storage container managed
	// by the queue.
	AzureArtifactRequest struct {

		// Artifact mime-type, when uploading artifact please use the same
		// `Content-Type`, consistently using the correct mime-type make
		// tooling a lot easier, specifically, always using `application/json`
		// for JSON artifacts.
		//
		// Max length: 255
		ContentType string `json:"contentType"`

		// Date-time after which the artifact should be deleted.
		// Note, that these will be collected over time, and artifacts may
		// remain available after expiration. Azure based artifacts are
		// identified in azure table storage and explicitly deleted in the
		// azure storage container after expiration.
		Expires tcclient.Time `json:"expires"`

		// Artifact storage type, in this case `azure`
		//
		// Possible values:
		//   * "azure"
		StorageType string `json:"storageType"`
	}

	// Response to a request for an Azure Shared Access Signature (SAS)
	// that will allow you to upload an artifact to an Azure blob storage
	// container managed by the queue.
	AzureArtifactResponse struct {

		// Artifact mime-type, should be specified with the
		// `x-ms-blob-content-type` when committing the block.
		//
		// Max length: 255
		ContentType string `json:"contentType"`

		// Date-time after which Shared Access Signature (SAS) will
		// seize to work.
		Expires tcclient.Time `json:"expires"`

		// Shared Access Signature (SAS) with write permissions, see
		// [Azure REST API]
		// (http://msdn.microsoft.com/en-US/library/azure/dn140256.aspx)
		// reference for details on how to use this.
		PutURL string `json:"putUrl"`

		// Artifact storage type, in this case `azure`
		//
		// Possible values:
		//   * "azure"
		StorageType string `json:"storageType"`
	}

	// Request a list of requests in a generalized format which can be run to
	// upload an artifact to storage managed by the queue.
	BlobArtifactRequest struct {

		// Optionally provide an encoding type which should be set as the HTTP
		// Content-Encoding header for this artifact.
		//
		// Max length: 255
		ContentEncoding string `json:"contentEncoding,omitempty"`

		// The number of bytes of the entire artifact.  This must be the number
		// of bytes in the file to be uploaded.  For single part uploads, the
		// upload will fail if the number of bytes uploaded does not match this
		// value.  A single part upload (e.g. no parts list) may be at most 5GB.
		// This limit is enforced in the code because it is not possible to
		// represent all of the restrictions in a json-schema.  A multipart
		// upload may be at most 5TB, with each part other than the last being
		// between 5MB and 5GB in size.
		//
		// Mininum:    0
		ContentLength int64 `json:"contentLength"`

		// The complete SHA256 value of the entire artifact.  This must be the
		// SHA256 of the file which is to be uploaded.  For single part uploads,
		// the upload will fail if the SHA256 value of what is uploaded does not
		// match this value
		//
		// Syntax:     ^[a-fA-F0-9]{64}$
		ContentSha256 string `json:"contentSha256"`

		// Artifact mime-type, when uploading artifact to the signed
		// `PUT` URL returned from this request this must given with the
		//  `ContentType` header. Please, provide correct mime-type,
		//  this make tooling a lot easier, specifically,
		//  always using `application/json` for JSON artifacts.
		//
		// Max length: 255
		ContentType string `json:"contentType"`

		// Date-time after which the artifact should be deleted. Note, that
		// these will be collected over time, and artifacts may remain
		// available after expiration. S3 based artifacts are identified in
		// azure table storage and explicitly deleted on S3 after expiration.
		Expires tcclient.Time `json:"expires"`

		// A list of parts for a multipart upload.  The presence of this list is
		// how a multipart upload is differentiated from a single part upload.
		// The items in this list represent individual parts for upload.  For a
		// multipart upload, the sha256 values provided here must match the
		// sha256 value that S3 internally computes for the upload to be
		// considered a success.  The overall sha256 value is not checked
		// explicitly because the S3 API does not allow for that, but the same
		// code that is responsible for generating the parts hashes would also
		// be generating the overall hash, which makes this less of a concern.
		// The worst case is that we have artifacts which incorrectly do not
		// validate, which is not as big of a security concern.
		Parts []MultipartPart `json:"parts,omitempty"`

		// Artifact storage type, in this case `'blob'`
		//
		// Possible values:
		//   * "blob"
		StorageType string `json:"storageType"`

		// The number of bytes transfered across the wire to the backing
		// datastore.  If specified, it represents the post-content-encoding
		// byte count
		//
		// Mininum:    0
		TransferLength int64 `json:"transferLength,omitempty"`

		// This is the sha256 of the bytes transfered across the wire to the
		// backing datastore.  If specified, it represents the
		// post-content-encoding sha256 value
		//
		// Syntax:     ^[a-fA-F0-9]{64}$
		TransferSha256 string `json:"transferSha256,omitempty"`
	}

	// Response to a request for creating a new blob artifact
	BlobArtifactResponse struct {

		// Date-time after which the signed `requests` no longer work
		Expires tcclient.Time `json:"expires"`

		// A list of generalized HTTP requests which must be run to upload the
		// artifact.
		Requests []HTTPRequest `json:"requests"`

		// Artifact storage type, in this case `'blob'`
		//
		// Possible values:
		//   * "blob"
		StorageType string `json:"storageType"`
	}

	// Request to claim a task for a worker to process.
	ClaimWorkRequest struct {

		// Number of tasks to attempt to claim.
		//
		// Default:    1
		// Mininum:    1
		// Maximum:    32
		Tasks int64 `json:"tasks"`

		// Identifier for group that worker claiming the task is a part of.
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerGroup string `json:"workerGroup"`

		// Identifier for worker within the given workerGroup
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerID string `json:"workerId"`
	}

	// Response to an attempt to claim tasks for a worker to process.
	ClaimWorkResponse struct {

		// List of task claims, may be empty if no tasks was claimed, in which case
		// the worker should sleep a tiny bit before polling again.
		Tasks []TaskClaim `json:"tasks"`
	}

	// Complete an aritifact
	CompleteArtifactRequest struct {

		// A list of the etags given by the API of the blob storage provider.  This is an opaque
		// string value provided by the API.
		//
		// Array items:
		Etags []string `json:"etags"`
	}

	// Response to a request for the number of pending tasks for a given
	// `provisionerId` and `workerType`.
	CountPendingTasksResponse struct {

		// An approximate number of pending tasks for the given `provisionerId` and
		// `workerType`. This is based on Azure Queue Storage metadata API, thus,
		// number of reported here may be higher than actual number of pending tasks.
		// But there cannot be more pending tasks reported here. Ie. this is an
		// **upper-bound** on the number of pending tasks.
		//
		// Mininum:    0
		PendingTasks int64 `json:"pendingTasks"`

		// Unique identifier for the provisioner
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		ProvisionerID string `json:"provisionerId"`

		// Identifier for worker type within the specified provisioner
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerType string `json:"workerType"`
	}

	// Request the queue to reply `424` (Failed Dependency) with `reason` and
	// `message` to any `GET` request for this artifact. This is mainly useful
	// as a way for a task to declare that it failed to provide an artifact it
	// wanted to upload.
	ErrorArtifactRequest struct {

		// Date-time after which the queue should stop replying with the error
		// and forget about the artifact.
		Expires tcclient.Time `json:"expires"`

		// Human readable explanation of why the artifact is missing
		//
		// Max length: 4096
		Message string `json:"message"`

		// Reason why the artifact doesn't exist.
		//
		// Possible values:
		//   * "file-missing-on-worker"
		//   * "invalid-resource-on-worker"
		//   * "too-large-file-on-worker"
		Reason string `json:"reason"`

		// Artifact storage type, in this case `error`
		//
		// Possible values:
		//   * "error"
		StorageType string `json:"storageType"`
	}

	// Response to a request for the queue to reply `424` (Failed Dependency)
	// with `reason` and `message` to any `GET` request for this artifact.
	ErrorArtifactResponse struct {

		// Artifact storage type, in this case `error`
		//
		// Possible values:
		//   * "error"
		StorageType string `json:"storageType"`
	}

	HTTPRequest struct {

		// Headers of request
		//
		// Map entries:
		Headers map[string]string `json:"headers"`

		// HTTP 1.1 method of request
		//
		// Possible values:
		//   * "GET"
		//   * "POST"
		//   * "PUT"
		//   * "DELETE"
		//   * "OPTIONS"
		//   * "HEAD"
		//   * "PATCH"
		Method string `json:"method"`

		// URL of request
		URL string `json:"url"`
	}

	// List of artifacts for a given `taskId` and `runId`.
	ListArtifactsResponse struct {

		// List of artifacts for given `taskId` and `runId`.
		Artifacts []Artifact `json:"artifacts"`

		// Opaque `continuationToken` to be given as query-string option to get the
		// next set of artifacts.
		// This property is only present if another request is necessary to fetch all
		// results. In practice the next request with a `continuationToken` may not
		// return additional results, but it can. Thus, you can only be sure to have
		// all the results if you've called with `continuationToken` until you get a
		// result without a `continuationToken`.
		ContinuationToken string `json:"continuationToken,omitempty"`
	}

	// Response from a `listDependentTasks` request.
	ListDependentTasksResponse struct {

		// Opaque `continuationToken` to be given as query-string option to get the
		// next set of dependent tasks.
		// This property is only present if another request is necessary to fetch all
		// results. In practice the next request with a `continuationToken` may not
		// return additional results, but it can. Thus, you can only be sure to have
		// all the results if you've called `listDependentTasks` with
		// `continuationToken` until you get a result without a `continuationToken`.
		ContinuationToken string `json:"continuationToken,omitempty"`

		// Identifier for the task whose dependents are being listed.
		//
		// Syntax:     ^[A-Za-z0-9_-]{8}[Q-T][A-Za-z0-9_-][CGKOSWaeimquy26-][A-Za-z0-9_-]{10}[AQgw]$
		TaskID string `json:"taskId"`

		// List of tasks that have `taskId` in the `task.dependencies` property.
		Tasks []TaskDefinitionAndStatus `json:"tasks"`
	}

	ListProvisionersResponse struct {

		// Opaque `continuationToken` to be given as query-string option to get the
		// next set of provisioners.
		// This property is only present if another request is necessary to fetch all
		// results. In practice the next request with a `continuationToken` may not
		// return additional results, but it can. Thus, you can only be sure to have
		// all the results if you've called with `continuationToken` until you get a
		// result without a `continuationToken`.
		ContinuationToken string `json:"continuationToken,omitempty"`

		Provisioners []ProvisionerInformation `json:"provisioners"`
	}

	// Response from a `listTaskGroup` request.
	ListTaskGroupResponse struct {

		// Opaque `continuationToken` to be given as query-string option to get the
		// next set of tasks in the task-group.
		// This property is only present if another request is necessary to fetch all
		// results. In practice the next request with a `continuationToken` may not
		// return additional results, but it can. Thus, you can only be sure to have
		// all the results if you've called `listTaskGroup` with `continuationToken`
		// until you get a result without a `continuationToken`.
		ContinuationToken string `json:"continuationToken,omitempty"`

		// Identifier for the task-group being listed.
		//
		// Syntax:     ^[A-Za-z0-9_-]{8}[Q-T][A-Za-z0-9_-][CGKOSWaeimquy26-][A-Za-z0-9_-]{10}[AQgw]$
		TaskGroupID string `json:"taskGroupId"`

		// List of tasks in this task-group.
		Tasks []TaskDefinitionAndStatus `json:"tasks"`
	}

	// Response from a `listWorkerTypes` request.
	ListWorkerTypesResponse struct {

		// Opaque `continuationToken` to be given as query-string option to get the
		// next set of worker-types in the provisioner.
		// This property is only present if another request is necessary to fetch all
		// results. In practice the next request with a `continuationToken` may not
		// return additional results, but it can. Thus, you can only be sure to have
		// all the results if you've called `listWorkerTypes` with `continuationToken`
		// until you get a result without a `continuationToken`.
		ContinuationToken string `json:"continuationToken,omitempty"`

		// List of worker-types in this provisioner.
		WorkerTypes []WorkerType `json:"workerTypes"`
	}

	// Response from a `listWorkers` request.
	ListWorkersResponse struct {

		// Opaque `continuationToken` to be given as query-string option to get the
		// next set of workers in the worker-type.
		// This property is only present if another request is necessary to fetch all
		// results. In practice the next request with a `continuationToken` may not
		// return additional results, but it can. Thus, you can only be sure to have
		// all the results if you've called `listWorkerTypes` with `continuationToken`
		// until you get a result without a `continuationToken`.
		ContinuationToken string `json:"continuationToken,omitempty"`

		// List of workers in this worker-type.
		Workers []Worker `json:"workers"`
	}

	MultipartPart struct {

		// The sha256 hash of the part.
		//
		// Syntax:     ^[a-fA-F0-9]{64}$
		// Min length: 64
		// Max length: 64
		Sha256 string `json:"sha256"`

		// The number of bytes in this part.  Keep in mind for S3 that
		// all but the last part must be minimum 5MB and the maximum for
		// a single part is 5GB.  The overall size may not exceed 5TB
		//
		// Mininum:    0
		Size int64 `json:"size"`
	}

	// Request a authorization to put and artifact or posting of a URL as an artifact. Note that the `storageType` property is referenced in the response as well.
	//
	// One of:
	//   * BlobArtifactRequest
	//   * S3ArtifactRequest
	//   * AzureArtifactRequest
	//   * RedirectArtifactRequest
	//   * ErrorArtifactRequest
	PostArtifactRequest json.RawMessage

	// Response to a request for posting an artifact.
	// Note that the `storageType` property is referenced in the request as well.
	//
	// One of:
	//   * BlobArtifactResponse
	//   * S3ArtifactResponse
	//   * AzureArtifactResponse
	//   * RedirectArtifactResponse
	//   * ErrorArtifactResponse
	PostArtifactResponse json.RawMessage

	ProvisionerInformation struct {

		// See taskcluster [actions](/docs/reference/platform/taskcluster-queue/docs/actions) documentation.
		Actions []Action `json:"actions"`

		// Description of the provisioner.
		Description string `json:"description"`

		// Date and time after which the provisioner created will be automatically
		// deleted by the queue.
		Expires tcclient.Time `json:"expires"`

		// Date and time where the provisioner was last seen active
		LastDateActive tcclient.Time `json:"lastDateActive"`

		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		ProvisionerID string `json:"provisionerId"`

		// This is the stability of the provisioner. Accepted values:
		//  * `experimental`
		//  * `stable`
		//  * `deprecated`
		//
		// Possible values:
		//   * "experimental"
		//   * "stable"
		//   * "deprecated"
		Stability string `json:"stability"`
	}

	// Request to update a provisioner.
	ProvisionerRequest struct {

		// See taskcluster [actions](/docs/reference/platform/taskcluster-queue/docs/actions) documentation.
		Actions []Action `json:"actions,omitempty"`

		// Description of the provisioner.
		Description string `json:"description,omitempty"`

		// Date and time after which the provisioner will be automatically
		// deleted by the queue.
		Expires tcclient.Time `json:"expires,omitempty"`

		// This is the stability of the provisioner. Accepted values:
		//   * `experimental`
		//   * `stable`
		//   * `deprecated`
		//
		// Possible values:
		//   * "experimental"
		//   * "stable"
		//   * "deprecated"
		Stability string `json:"stability,omitempty"`
	}

	// Response containing information about a provisioner.
	ProvisionerResponse struct {

		// See taskcluster [actions](/docs/reference/platform/taskcluster-queue/docs/actions) documentation.
		Actions []Action `json:"actions"`

		// Description of the provisioner.
		Description string `json:"description"`

		// Date and time after which the provisioner will be automatically
		// deleted by the queue.
		Expires tcclient.Time `json:"expires"`

		// Date of the last time this provisioner was seen active. `lastDateActive` is updated every 6 hours
		// but may be off by up-to 6 hours. Nonetheless, `lastDateActive` is a good indicator
		// of when the provisioner was last seen active.
		LastDateActive tcclient.Time `json:"lastDateActive"`

		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		ProvisionerID string `json:"provisionerId"`

		// This is the stability of the provisioner. Accepted values:
		//   * `experimental`
		//   * `stable`
		//   * `deprecated`
		//
		// Possible values:
		//   * "experimental"
		//   * "stable"
		//   * "deprecated"
		Stability string `json:"stability"`
	}

	// Request to update a worker's quarantineUntil property.
	QuarantineWorkerRequest struct {

		// Quarantining a worker allows the machine to remain alive but not accept jobs.
		// Once the quarantineUntil time has elapsed, the worker resumes accepting jobs.
		// Note that a quarantine can be lifted by setting `quarantineUntil` to the present time (or
		// somewhere in the past).
		QuarantineUntil tcclient.Time `json:"quarantineUntil"`
	}

	// Request the queue to redirect to a URL for a given artifact.
	// This allows you to reference artifacts that aren't managed by the queue.
	// The queue will still authenticate the request, so depending on the level
	// of secrecy required, secret URLs **might** work. Note, this is mainly
	// useful for public artifacts, for example temporary files directly
	// stored on the worker host and only available there for a specific
	// amount of time.
	RedirectArtifactRequest struct {

		// Artifact mime-type for the resource to which the queue should
		// redirect. Please use the same `Content-Type`, consistently using
		// the correct mime-type make tooling a lot easier, specifically,
		// always using `application/json` for JSON artifacts.
		//
		// Max length: 255
		ContentType string `json:"contentType"`

		// Date-time after which the queue should no longer redirect to this URL.
		// Note, that the queue will and cannot delete the resource your URL
		// references, you are responsible for doing that yourself.
		Expires tcclient.Time `json:"expires"`

		// Artifact storage type, in this case `reference`
		//
		// Possible values:
		//   * "reference"
		StorageType string `json:"storageType"`

		// URL to which the queue should redirect using a `303` (See other)
		// redirect.
		URL string `json:"url"`
	}

	// Response to a request for the queue to redirect to a URL for a given
	// artifact.
	RedirectArtifactResponse struct {

		// Artifact storage type, in this case `reference`
		//
		// Possible values:
		//   * "reference"
		StorageType string `json:"storageType"`
	}

	// JSON object with information about a run
	RunInformation struct {

		// Reason for the creation of this run,
		// **more reasons may be added in the future**.
		//
		// Possible values:
		//   * "scheduled"
		//   * "retry"
		//   * "task-retry"
		//   * "rerun"
		//   * "exception"
		ReasonCreated string `json:"reasonCreated"`

		// Reason that run was resolved, this is mainly
		// useful for runs resolved as `exception`.
		// Note, **more reasons may be added in the future**, also this
		// property is only available after the run is resolved. Some of these
		// reasons, notably `intermittent-task`, `worker-shutdown`, and
		// `claim-expired`, will trigger an automatic retry of the task.
		//
		// Possible values:
		//   * "completed"
		//   * "failed"
		//   * "deadline-exceeded"
		//   * "canceled"
		//   * "superseded"
		//   * "claim-expired"
		//   * "worker-shutdown"
		//   * "malformed-payload"
		//   * "resource-unavailable"
		//   * "internal-error"
		//   * "intermittent-task"
		ReasonResolved string `json:"reasonResolved,omitempty"`

		// Date-time at which this run was resolved, ie. when the run changed
		// state from `running` to either `completed`, `failed` or `exception`.
		// This property is only present after the run as been resolved.
		Resolved tcclient.Time `json:"resolved,omitempty"`

		// Id of this task run, `run-id`s always starts from `0`
		//
		// Mininum:    0
		// Maximum:    1000
		RunID int64 `json:"runId"`

		// Date-time at which this run was scheduled, ie. when the run was
		// created in state `pending`.
		Scheduled tcclient.Time `json:"scheduled"`

		// Date-time at which this run was claimed, ie. when the run changed
		// state from `pending` to `running`. This property is only present
		// after the run has been claimed.
		Started tcclient.Time `json:"started,omitempty"`

		// State of this run
		//
		// Possible values:
		//   * "pending"
		//   * "running"
		//   * "completed"
		//   * "failed"
		//   * "exception"
		State string `json:"state"`

		// Time at which the run expires and is resolved as `failed`, if the
		// run isn't reclaimed. Note, only present after the run has been
		// claimed.
		TakenUntil tcclient.Time `json:"takenUntil,omitempty"`

		// Identifier for group that worker who executes this run is a part of,
		// this identifier is mainly used for efficient routing.
		// Note, this property is only present after the run is claimed.
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerGroup string `json:"workerGroup,omitempty"`

		// Identifier for worker evaluating this run within given
		// `workerGroup`. Note, this property is only available after the run
		// has been claimed.
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerID string `json:"workerId,omitempty"`
	}

	// Request for a signed PUT URL that will allow you to upload an artifact
	// to an S3 bucket managed by the queue.
	S3ArtifactRequest struct {

		// Artifact mime-type, when uploading artifact to the signed
		// `PUT` URL returned from this request this must given with the
		//  `ContentType` header. Please, provide correct mime-type,
		//  this make tooling a lot easier, specifically,
		//  always using `application/json` for JSON artifacts.
		//
		// Max length: 255
		ContentType string `json:"contentType"`

		// Date-time after which the artifact should be deleted. Note, that
		// these will be collected over time, and artifacts may remain
		// available after expiration. S3 based artifacts are identified in
		// azure table storage and explicitly deleted on S3 after expiration.
		Expires tcclient.Time `json:"expires"`

		// Artifact storage type, in this case `'s3'`
		//
		// Possible values:
		//   * "s3"
		StorageType string `json:"storageType"`
	}

	// Response to a request for a signed PUT URL that will allow you to
	// upload an artifact to an S3 bucket managed by the queue.
	S3ArtifactResponse struct {

		// Artifact mime-type, must be specified as header when uploading with
		// the signed `putUrl`.
		//
		// Max length: 255
		ContentType string `json:"contentType"`

		// Date-time after which the signed `putUrl` no longer works
		Expires tcclient.Time `json:"expires"`

		// URL to which a `PUT` request can be made to upload the artifact
		// requested. Note, the `Content-Length` must be specified correctly,
		// and the `ContentType` header must be set the value specified below.
		PutURL string `json:"putUrl"`

		// Artifact storage type, in this case `'s3'`
		//
		// Possible values:
		//   * "s3"
		StorageType string `json:"storageType"`
	}

	TaskClaim struct {

		// Temporary credentials granting `task.scopes` and the scope:
		// `queue:claim-task:<taskId>/<runId>` which allows the worker to reclaim
		// the task, upload artifacts and report task resolution.
		//
		// The temporary credentials are set to expire after `takenUntil`. They
		// won't expire exactly at `takenUntil` but shortly after, hence, requests
		// coming close `takenUntil` won't have problems even if there is a little
		// clock drift.
		//
		// Workers should use these credentials when making requests on behalf of
		// a task. This includes requests to create artifacts, reclaiming the task
		// reporting the task `completed`, `failed` or `exception`.
		//
		// Note, a new set of temporary credentials is issued when the worker
		// reclaims the task.
		Credentials TaskCredentials `json:"credentials"`

		// `run-id` assigned to this run of the task
		//
		// Mininum:    0
		// Maximum:    1000
		RunID int64 `json:"runId"`

		// A representation of **task status** as known by the queue
		Status TaskStatusStructure `json:"status"`

		// Time at which the run expires and is resolved as `exception`,
		// with reason `claim-expired` if the run haven't been reclaimed.
		TakenUntil tcclient.Time `json:"takenUntil"`

		// Definition of a task that can be scheduled
		Task TaskDefinitionResponse `json:"task"`

		// Identifier for the worker-group within which this run started.
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerGroup string `json:"workerGroup"`

		// Identifier for the worker executing this run.
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerID string `json:"workerId"`
	}

	// Request to claim (or reclaim) a task
	TaskClaimRequest struct {

		// Identifier for group that worker claiming the task is a part of.
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerGroup string `json:"workerGroup"`

		// Identifier for worker within the given workerGroup
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerID string `json:"workerId"`
	}

	// Response to a successful task claim
	TaskClaimResponse struct {

		// Temporary credentials granting `task.scopes` and the scope:
		// `queue:claim-task:<taskId>/<runId>` which allows the worker to reclaim
		// the task, upload artifacts and report task resolution.
		//
		// The temporary credentials are set to expire after `takenUntil`. They
		// won't expire exactly at `takenUntil` but shortly after, hence, requests
		// coming close `takenUntil` won't have problems even if there is a little
		// clock drift.
		//
		// Workers should use these credentials when making requests on behalf of
		// a task. This includes requests to create artifacts, reclaiming the task
		// reporting the task `completed`, `failed` or `exception`.
		//
		// Note, a new set of temporary credentials is issued when the worker
		// reclaims the task.
		Credentials TaskCredentials `json:"credentials"`

		// `run-id` assigned to this run of the task
		//
		// Mininum:    0
		// Maximum:    1000
		RunID int64 `json:"runId"`

		// A representation of **task status** as known by the queue
		Status TaskStatusStructure `json:"status"`

		// Time at which the run expires and is resolved as `exception`,
		// with reason `claim-expired` if the run haven't been reclaimed.
		TakenUntil tcclient.Time `json:"takenUntil"`

		// Definition of a task that can be scheduled
		Task TaskDefinitionResponse `json:"task"`

		// Identifier for the worker-group within which this run started.
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerGroup string `json:"workerGroup"`

		// Identifier for the worker executing this run.
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerID string `json:"workerId"`
	}

	// Temporary credentials granting `task.scopes` and the scope:
	// `queue:claim-task:<taskId>/<runId>` which allows the worker to reclaim
	// the task, upload artifacts and report task resolution.
	//
	// The temporary credentials are set to expire after `takenUntil`. They
	// won't expire exactly at `takenUntil` but shortly after, hence, requests
	// coming close `takenUntil` won't have problems even if there is a little
	// clock drift.
	//
	// Workers should use these credentials when making requests on behalf of
	// a task. This includes requests to create artifacts, reclaiming the task
	// reporting the task `completed`, `failed` or `exception`.
	//
	// Note, a new set of temporary credentials is issued when the worker
	// reclaims the task.
	TaskCredentials struct {

		// The `accessToken` for the temporary credentials.
		//
		// Min length: 1
		AccessToken string `json:"accessToken"`

		// The `certificate` for the temporary credentials, these are required
		// for the temporary credentials to work.
		//
		// Min length: 1
		Certificate string `json:"certificate"`

		// The `clientId` for the temporary credentials.
		//
		// Min length: 1
		ClientID string `json:"clientId"`
	}

	// Task Definition and task status structure.
	TaskDefinitionAndStatus struct {

		// A representation of **task status** as known by the queue
		Status TaskStatusStructure `json:"status"`

		// Definition of a task that can be scheduled
		Task TaskDefinitionResponse `json:"task"`
	}

	// Definition of a task that can be scheduled
	TaskDefinitionRequest struct {

		// Creation time of task
		Created tcclient.Time `json:"created"`

		// Deadline of the task, `pending` and `running` runs are
		// resolved as **exception** if not resolved by other means
		// before the deadline. Note, deadline cannot be more than
		// 5 days into the future
		Deadline tcclient.Time `json:"deadline"`

		// List of dependent tasks. These must either be _completed_ or _resolved_
		// before this task is scheduled. See `requires` for semantics.
		//
		// Default:    []
		//
		// Array items:
		// The `taskId` of a task that must be resolved before this task is
		// scheduled.
		//
		// Syntax:     ^[A-Za-z0-9_-]{8}[Q-T][A-Za-z0-9_-][CGKOSWaeimquy26-][A-Za-z0-9_-]{10}[AQgw]$
		Dependencies []string `json:"dependencies,omitempty"`

		// Task expiration, time at which task definition and status is deleted.
		// Notice that all artifacts for the task must have an expiration that is no
		// later than this. If this property isn't it will be set to `deadline`
		// plus one year (this default may change).
		Expires tcclient.Time `json:"expires,omitempty"`

		// Object with properties that can hold any kind of extra data that should be
		// associated with the task. This can be data for the task which doesn't
		// fit into `payload`, or it can supplementary data for use in services
		// listening for events from this task. For example this could be details to
		// display on _treeherder_, or information for indexing the task. Please, try
		// to put all related information under one property, so `extra` data keys
		// for treeherder reporting and task indexing don't conflict, hence, we have
		// reusable services. **Warning**, do not stuff large data-sets in here --
		// task definitions should not take-up multiple MiBs.
		//
		// Default:    {}
		//
		// Additional properties allowed
		Extra json.RawMessage `json:"extra,omitempty"`

		// Required task metadata
		Metadata TaskMetadata `json:"metadata"`

		// Task-specific payload following worker-specific format.
		// Refer to the documentation for the worker implementing
		// `<provisionerId>/<workerType>` for details.
		//
		// Additional properties allowed
		Payload json.RawMessage `json:"payload"`

		// Priority of task. This defaults to `lowest` and the scope
		// `queue:create-task:<priority>/<provisionerId>/<workerType>` is required
		// to define a task with `<priority>`. The `normal` priority is treated as
		// `lowest`.
		//
		// Possible values:
		//   * "highest"
		//   * "very-high"
		//   * "high"
		//   * "medium"
		//   * "low"
		//   * "very-low"
		//   * "lowest"
		//   * "normal"
		//
		// Default:    "lowest"
		Priority string `json:"priority,omitempty"`

		// Unique identifier for a provisioner, that can supply specified
		// `workerType`
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		ProvisionerID string `json:"provisionerId"`

		// The tasks relation to its dependencies. This property specifies the
		// semantics of the `task.dependencies` property.
		// If `all-completed` is given the task will be scheduled when all
		// dependencies are resolved _completed_ (successful resolution).
		// If `all-resolved` is given the task will be scheduled when all dependencies
		// have been resolved, regardless of what their resolution is.
		//
		// Possible values:
		//   * "all-completed"
		//   * "all-resolved"
		//
		// Default:    "all-completed"
		Requires string `json:"requires,omitempty"`

		// Number of times to retry the task in case of infrastructure issues.
		// An _infrastructure issue_ is a worker node that crashes or is shutdown,
		// these events are to be expected.
		//
		// Default:    5
		// Mininum:    0
		// Maximum:    49
		Retries int64 `json:"retries,omitempty"`

		// List of task-specific routes. Pulse messages about the task will be CC'ed to
		// `route.<value>` for each `<value>` in this array.
		//
		// Default:    []
		//
		// Array items:
		// A task specific route.
		//
		// Min length: 1
		// Max length: 249
		Routes []string `json:"routes,omitempty"`

		// All tasks in a task group must have the same `schedulerId`. This is used for several purposes:
		//
		// * it can represent the entity that created the task;
		// * it can limit addition of new tasks to a task group: the caller of
		//     `createTask` must have a scope related to the `schedulerId` of the task
		//     group;
		// * it controls who can manipulate tasks, again by requiring
		//     `schedulerId`-related scopes; and
		// * it appears in the routing key for Pulse messages about the task.
		//
		// Default:    "-"
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		SchedulerID string `json:"schedulerId,omitempty"`

		// List of scopes that the task is authorized to use during its execution.
		//
		// Array items:
		// A single scope. A scope must be composed of
		// printable ASCII characters and spaces.  Scopes ending in more than
		// one `*` character are forbidden.
		//
		// Syntax:     ^[ -~]*$
		Scopes []string `json:"scopes,omitempty"`

		// Arbitrary key-value tags (only strings limited to 4k). These can be used
		// to attach informal metadata to a task. Use this for informal tags that
		// tasks can be classified by. You can also think of strings here as
		// candidates for formal metadata. Something like
		// `purpose: 'build' || 'test'` is a good example.
		//
		// Default:    {}
		//
		// Map entries:
		// Max length: 4096
		Tags map[string]string `json:"tags,omitempty"`

		// Identifier for a group of tasks scheduled together with this task.
		// Generally, all tasks related to a single event such as a version-control
		// push or a nightly build have the same `taskGroupId`.  This property
		// defaults to `taskId` if it isn't specified.  Tasks with `taskId` equal to
		// the `taskGroupId` are, [by convention](/docs/manual/using/task-graph),
		// decision tasks.
		//
		// Syntax:     ^[A-Za-z0-9_-]{8}[Q-T][A-Za-z0-9_-][CGKOSWaeimquy26-][A-Za-z0-9_-]{10}[AQgw]$
		TaskGroupID string `json:"taskGroupId,omitempty"`

		// Unique identifier for a worker-type within a specific provisioner
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerType string `json:"workerType"`
	}

	// Definition of a task that can be scheduled
	TaskDefinitionResponse struct {

		// Creation time of task
		Created tcclient.Time `json:"created"`

		// Deadline of the task, `pending` and `running` runs are
		// resolved as **exception** if not resolved by other means
		// before the deadline. Note, deadline cannot be more than
		// 5 days into the future
		Deadline tcclient.Time `json:"deadline"`

		// List of dependent tasks. These must either be _completed_ or _resolved_
		// before this task is scheduled. See `requires` for semantics.
		//
		// Default:    []
		//
		// Array items:
		// The `taskId` of a task that must be resolved before this task is
		// scheduled.
		//
		// Syntax:     ^[A-Za-z0-9_-]{8}[Q-T][A-Za-z0-9_-][CGKOSWaeimquy26-][A-Za-z0-9_-]{10}[AQgw]$
		Dependencies []string `json:"dependencies"`

		// Task expiration, time at which task definition and status is deleted.
		// Notice that all artifacts for the task must have an expiration that is no
		// later than this. If this property isn't it will be set to `deadline`
		// plus one year (this default may change).
		Expires tcclient.Time `json:"expires,omitempty"`

		// Object with properties that can hold any kind of extra data that should be
		// associated with the task. This can be data for the task which doesn't
		// fit into `payload`, or it can supplementary data for use in services
		// listening for events from this task. For example this could be details to
		// display on _treeherder_, or information for indexing the task. Please, try
		// to put all related information under one property, so `extra` data keys
		// for treeherder reporting and task indexing don't conflict, hence, we have
		// reusable services. **Warning**, do not stuff large data-sets in here --
		// task definitions should not take-up multiple MiBs.
		//
		// Default:    {}
		//
		// Additional properties allowed
		Extra json.RawMessage `json:"extra"`

		// Required task metadata
		Metadata TaskMetadata `json:"metadata"`

		// Task-specific payload following worker-specific format.
		// Refer to the documentation for the worker implementing
		// `<provisionerId>/<workerType>` for details.
		//
		// Additional properties allowed
		Payload json.RawMessage `json:"payload"`

		// Priority of task. This defaults to `lowest` and the scope
		// `queue:create-task:<priority>/<provisionerId>/<workerType>` is required
		// to define a task with `<priority>`. The `normal` priority is treated as
		// `lowest`.
		//
		// Possible values:
		//   * "highest"
		//   * "very-high"
		//   * "high"
		//   * "medium"
		//   * "low"
		//   * "very-low"
		//   * "lowest"
		//   * "normal"
		//
		// Default:    "lowest"
		Priority string `json:"priority"`

		// Unique identifier for a provisioner, that can supply specified
		// `workerType`
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		ProvisionerID string `json:"provisionerId"`

		// The tasks relation to its dependencies. This property specifies the
		// semantics of the `task.dependencies` property.
		// If `all-completed` is given the task will be scheduled when all
		// dependencies are resolved _completed_ (successful resolution).
		// If `all-resolved` is given the task will be scheduled when all dependencies
		// have been resolved, regardless of what their resolution is.
		//
		// Possible values:
		//   * "all-completed"
		//   * "all-resolved"
		//
		// Default:    "all-completed"
		Requires string `json:"requires"`

		// Number of times to retry the task in case of infrastructure issues.
		// An _infrastructure issue_ is a worker node that crashes or is shutdown,
		// these events are to be expected.
		//
		// Default:    5
		// Mininum:    0
		// Maximum:    49
		Retries int64 `json:"retries"`

		// List of task-specific routes. Pulse messages about the task will be CC'ed to
		// `route.<value>` for each `<value>` in this array.
		//
		// Default:    []
		//
		// Array items:
		// A task specific route.
		//
		// Min length: 1
		// Max length: 249
		Routes []string `json:"routes"`

		// All tasks in a task group must have the same `schedulerId`. This is used for several purposes:
		//
		// * it can represent the entity that created the task;
		// * it can limit addition of new tasks to a task group: the caller of
		//     `createTask` must have a scope related to the `schedulerId` of the task
		//     group;
		// * it controls who can manipulate tasks, again by requiring
		//     `schedulerId`-related scopes; and
		// * it appears in the routing key for Pulse messages about the task.
		//
		// Default:    "-"
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		SchedulerID string `json:"schedulerId"`

		// List of scopes that the task is authorized to use during its execution.
		//
		// Array items:
		// A single scope. A scope must be composed of
		// printable ASCII characters and spaces.  Scopes ending in more than
		// one `*` character are forbidden.
		//
		// Syntax:     ^[ -~]*$
		Scopes []string `json:"scopes"`

		// Arbitrary key-value tags (only strings limited to 4k). These can be used
		// to attach informal metadata to a task. Use this for informal tags that
		// tasks can be classified by. You can also think of strings here as
		// candidates for formal metadata. Something like
		// `purpose: 'build' || 'test'` is a good example.
		//
		// Default:    {}
		//
		// Map entries:
		// Max length: 4096
		Tags map[string]string `json:"tags"`

		// Identifier for a group of tasks scheduled together with this task.
		// Generally, all tasks related to a single event such as a version-control
		// push or a nightly build have the same `taskGroupId`.  This property
		// defaults to `taskId` if it isn't specified.  Tasks with `taskId` equal to
		// the `taskGroupId` are, [by convention](/docs/manual/using/task-graph),
		// decision tasks.
		//
		// Syntax:     ^[A-Za-z0-9_-]{8}[Q-T][A-Za-z0-9_-][CGKOSWaeimquy26-][A-Za-z0-9_-]{10}[AQgw]$
		TaskGroupID string `json:"taskGroupId"`

		// Unique identifier for a worker-type within a specific provisioner
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerType string `json:"workerType"`
	}

	// Request for a run of a task to be resolved with an exception
	TaskExceptionRequest struct {

		// Reason that the task is resolved with an exception. This is a subset
		// of the values for `resolvedReason` given in the task status structure.
		// **Report `worker-shutdown`** if the run failed because the worker
		// had to shutdown (spot node disappearing). In case of `worker-shutdown`
		// the queue will immediately **retry** the task, by making a new run.
		// This is much faster than ignoreing the issue and letting the task _retry_
		// by claim expiration. For any other _reason_ reported the queue will not
		// retry the task.
		// **Report `malformed-payload`** if the `task.payload` doesn't match the
		// schema for the worker payload, or referenced resource doesn't exists.
		// In either case, you should still log the error to a log file for the
		// specific run.
		// **Report `resource-unavailable`** if a resource/service needed or
		// referenced in `task.payload` is _temporarily_ unavailable. Do not use this
		// unless you know the resource exists, if the resource doesn't exist you
		// should report `malformed-payload`. Example use-case if you contact the
		// index (a service) on behalf of the task, because of a declaration in
		// `task.payload`, and the service (index) is temporarily down. Don't use
		// this if a URL returns 404, but if it returns 503 or hits a timeout when
		// you retry the request, then this _may_ be a valid exception. The queue
		// assumes that workers have applied retries as needed, and will not retry
		//  the task.
		// **Report `internal-error`** if the worker experienced an unhandled internal
		// error from which it couldn't recover. The queue will not retry runs
		// resolved with this reason, but you are clearly signaling that this is a
		// bug in the worker code.
		// **Report `superseded`** if the task was determined to have been
		// superseded by another task, and its results are no longer needed.  It is
		// convention in this case to create an artifact entitled
		// `public/superseded-by` containing the taskId of the task that superseded
		// this one.
		// **Report `intermittent-task`** if the task explicitly requested a retry
		// because task is intermittent. Workers can choose whether or not to
		// support this, but workers shouldn't blindly report this for every task
		// that fails.
		//
		// Possible values:
		//   * "worker-shutdown"
		//   * "malformed-payload"
		//   * "resource-unavailable"
		//   * "internal-error"
		//   * "superseded"
		//   * "intermittent-task"
		Reason string `json:"reason"`
	}

	// Required task metadata
	TaskMetadata struct {

		// Human readable description of the task, please **explain** what the
		// task does. A few lines of documentation is not going to hurt you.
		//
		// Max length: 32768
		Description string `json:"description"`

		// Human readable name of task, used to very briefly given an idea about
		// what the task does.
		//
		// Max length: 255
		Name string `json:"name"`

		// E-mail of person who caused this task, e.g. the person who did
		// `hg push`. The person we should contact to ask why this task is here.
		//
		// Max length: 255
		Owner string `json:"owner"`

		// Link to source of this task, should specify a file, revision and
		// repository. This should be place someone can go an do a git/hg blame
		// to who came up with recipe for this task.
		//
		// Syntax:     ^https?://
		// Max length: 4096
		Source string `json:"source"`
	}

	// Response to a successful task claim
	TaskReclaimResponse struct {

		// Temporary credentials granting `task.scopes` and the scope:
		// `queue:claim-task:<taskId>/<runId>` which allows the worker to reclaim
		// the task, upload artifacts and report task resolution.
		//
		// The temporary credentials are set to expire after `takenUntil`. They
		// won't expire exactly at `takenUntil` but shortly after, hence, requests
		// coming close `takenUntil` won't have problems even if there is a little
		// clock drift.
		//
		// Workers should use these credentials when making requests on behalf of
		// a task. This includes requests to create artifacts, reclaiming the task
		// reporting the task `completed`, `failed` or `exception`.
		//
		// Note, a new set of temporary credentials is issued when the worker
		// reclaims the task.
		Credentials TaskCredentials `json:"credentials"`

		// `run-id` assigned to this run of the task
		//
		// Mininum:    0
		// Maximum:    1000
		RunID int64 `json:"runId"`

		// A representation of **task status** as known by the queue
		Status TaskStatusStructure `json:"status"`

		// Time at which the run expires and is resolved as `exception`,
		// with reason `claim-expired` if the run haven't been reclaimed.
		TakenUntil tcclient.Time `json:"takenUntil"`

		// Identifier for the worker-group within which this run started.
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerGroup string `json:"workerGroup"`

		// Identifier for the worker executing this run.
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerID string `json:"workerId"`
	}

	// A run of a task.
	TaskRun struct {

		// Id of this task run, `run-id`s always starts from `0`
		//
		// Mininum:    0
		// Maximum:    1000
		RunID int64 `json:"runId"`

		// Unique task identifier, this is UUID encoded as
		// [URL-safe base64](http://tools.ietf.org/html/rfc4648#section-5) and
		// stripped of `=` padding.
		//
		// Syntax:     ^[A-Za-z0-9_-]{8}[Q-T][A-Za-z0-9_-][CGKOSWaeimquy26-][A-Za-z0-9_-]{10}[AQgw]$
		TaskID string `json:"taskId"`
	}

	// Response to a task status request
	TaskStatusResponse struct {

		// A representation of **task status** as known by the queue
		Status TaskStatusStructure `json:"status"`
	}

	// A representation of **task status** as known by the queue
	TaskStatusStructure struct {

		// Deadline of the task, `pending` and `running` runs are
		// resolved as **exception** if not resolved by other means
		// before the deadline. Note, deadline cannot be more than
		// 5 days into the future
		Deadline tcclient.Time `json:"deadline"`

		// Task expiration, time at which task definition and
		// status is deleted. Notice that all artifacts for the task
		// must have an expiration that is no later than this.
		Expires tcclient.Time `json:"expires"`

		// Unique identifier for a provisioner, that can supply specified
		// `workerType`
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		ProvisionerID string `json:"provisionerId"`

		// Number of retries left for the task in case of infrastructure issues
		//
		// Mininum:    0
		// Maximum:    999
		RetriesLeft int64 `json:"retriesLeft"`

		// List of runs, ordered so that index `i` has `runId == i`
		Runs []RunInformation `json:"runs"`

		// All tasks in a task group must have the same `schedulerId`. This is used for several purposes:
		//
		// * it can represent the entity that created the task;
		// * it can limit addition of new tasks to a task group: the caller of
		//     `createTask` must have a scope related to the `schedulerId` of the task
		//     group;
		// * it controls who can manipulate tasks, again by requiring
		//     `schedulerId`-related scopes; and
		// * it appears in the routing key for Pulse messages about the task.
		//
		// Default:    "-"
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		SchedulerID string `json:"schedulerId"`

		// State of this task. This is just an auxiliary property derived from state
		// of latests run, or `unscheduled` if none.
		//
		// Possible values:
		//   * "unscheduled"
		//   * "pending"
		//   * "running"
		//   * "completed"
		//   * "failed"
		//   * "exception"
		State string `json:"state"`

		// Identifier for a group of tasks scheduled together with this task.
		// Generally, all tasks related to a single event such as a version-control
		// push or a nightly build have the same `taskGroupId`.  This property
		// defaults to `taskId` if it isn't specified.  Tasks with `taskId` equal to
		// the `taskGroupId` are, [by convention](/docs/manual/using/task-graph),
		// decision tasks.
		//
		// Syntax:     ^[A-Za-z0-9_-]{8}[Q-T][A-Za-z0-9_-][CGKOSWaeimquy26-][A-Za-z0-9_-]{10}[AQgw]$
		TaskGroupID string `json:"taskGroupId"`

		// Unique task identifier, this is UUID encoded as
		// [URL-safe base64](http://tools.ietf.org/html/rfc4648#section-5) and
		// stripped of `=` padding.
		//
		// Syntax:     ^[A-Za-z0-9_-]{8}[Q-T][A-Za-z0-9_-][CGKOSWaeimquy26-][A-Za-z0-9_-]{10}[AQgw]$
		TaskID string `json:"taskId"`

		// Unique identifier for a worker-type within a specific provisioner
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerType string `json:"workerType"`
	}

	Worker struct {

		// Date of the first time this worker claimed a task.
		FirstClaim tcclient.Time `json:"firstClaim"`

		// A run of a task.
		LatestTask TaskRun `json:"latestTask,omitempty"`

		// Quarantining a worker allows the machine to remain alive but not accept jobs.
		// Once the quarantineUntil time has elapsed, the worker resumes accepting jobs.
		// Note that a quarantine can be lifted by setting `quarantineUntil` to the present time (or
		// somewhere in the past).
		QuarantineUntil tcclient.Time `json:"quarantineUntil,omitempty"`

		// Identifier for the worker group containing this worker.
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerGroup string `json:"workerGroup"`

		// Identifier for this worker (unique within this worker group).
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerID string `json:"workerId"`
	}

	// Actions provide a generic mechanism to expose additional features of a
	// provisioner, worker type, or worker to Taskcluster clients.
	//
	// An action is comprised of metadata describing the feature it exposes,
	// together with a webhook for triggering it.
	//
	// The Taskcluster tools site, for example, retrieves actions when displaying
	// provisioners, worker types and workers. It presents the provisioner/worker
	// type/worker specific actions to the user. When the user triggers an action,
	// the web client takes the registered webhook, substitutes parameters into the
	// URL (see `url`), signs the requests with the Taskcluster credentials of the
	// user operating the web interface, and issues the HTTP request.
	//
	// The level to which the action relates (provisioner, worker type, worker) is
	// called the action context. All actions, regardless of the action contexts,
	// are registered against the provisioner when calling
	// `queue.declareProvisioner`.
	//
	// The action context is used by the web client to determine where in the web
	// interface to present the action to the user as follows:
	//
	// | `context`   | Tool where action is displayed |
	// |-------------|--------------------------------|
	// | provisioner | Provisioner Explorer           |
	// | worker-type | Workers Explorer               |
	// | worker      | Worker Explorer                |
	//
	// See [actions docs](/docs/reference/platform/taskcluster-queue/docs/actions)
	// for more information.
	WorkerAction struct {

		// Only actions with the context `worker` are included.
		//
		// Possible values:
		//   * "worker"
		Context string `json:"context"`

		// Description of the provisioner.
		Description string `json:"description"`

		// Method to indicate the desired action to be performed for a given resource.
		//
		// Possible values:
		//   * "POST"
		//   * "PUT"
		//   * "DELETE"
		//   * "PATCH"
		Method string `json:"method"`

		// Short names for things like logging/error messages.
		Name string `json:"name"`

		// Appropriate title for any sort of Modal prompt.
		Title json.RawMessage `json:"title"`

		// When an action is triggered, a request is made using the `url` and `method`.
		// Depending on the `context`, the following parameters will be substituted in the url:
		//
		// | `context`   | Path parameters                                          |
		// |-------------|----------------------------------------------------------|
		// | provisioner | <provisionerId>                                          |
		// | worker-type | <provisionerId>, <workerType>                            |
		// | worker      | <provisionerId>, <workerType>, <workerGroup>, <workerId> |
		//
		// _Note: The request needs to be signed with the user's Taskcluster credentials._
		URL string `json:"url"`
	}

	// Request to update a worker.
	WorkerRequest struct {

		// Date and time after which the worker will be automatically
		// deleted by the queue.
		Expires tcclient.Time `json:"expires,omitempty"`
	}

	// Response containing information about a worker.
	WorkerResponse struct {
		Actions []WorkerAction `json:"actions"`

		// Date and time after which the worker will be automatically
		// deleted by the queue.
		Expires tcclient.Time `json:"expires"`

		// Date of the first time this worker claimed a task.
		FirstClaim tcclient.Time `json:"firstClaim"`

		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		ProvisionerID string `json:"provisionerId"`

		// Quarantining a worker allows the machine to remain alive but not accept jobs.
		// Once the quarantineUntil time has elapsed, the worker resumes accepting jobs.
		// Note that a quarantine can be lifted by setting `quarantineUntil` to the present time (or
		// somewhere in the past).
		QuarantineUntil tcclient.Time `json:"quarantineUntil,omitempty"`

		// List of 20 most recent tasks claimed by the worker.
		RecentTasks []TaskRun `json:"recentTasks"`

		// Identifier for group that worker who executes this run is a part of,
		// this identifier is mainly used for efficient routing.
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerGroup string `json:"workerGroup"`

		// Identifier for worker evaluating this run within given
		// `workerGroup`.
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerID string `json:"workerId"`

		// WorkerType name.
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerType string `json:"workerType"`
	}

	WorkerType struct {

		// Description of the worker-type.
		Description string `json:"description"`

		// Date and time after which the worker-type will be automatically
		// deleted by the queue.
		Expires tcclient.Time `json:"expires"`

		// Date and time where the worker-type was last seen active
		LastDateActive tcclient.Time `json:"lastDateActive"`

		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		ProvisionerID string `json:"provisionerId"`

		// This is the stability of the worker-type. Accepted values:
		//  * `experimental`
		//  * `stable`
		//  * `deprecated`
		//
		// Possible values:
		//   * "experimental"
		//   * "stable"
		//   * "deprecated"
		Stability string `json:"stability"`

		// WorkerType name.
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerType string `json:"workerType"`
	}

	// Actions provide a generic mechanism to expose additional features of a
	// provisioner, worker type, or worker to Taskcluster clients.
	//
	// An action is comprised of metadata describing the feature it exposes,
	// together with a webhook for triggering it.
	//
	// The Taskcluster tools site, for example, retrieves actions when displaying
	// provisioners, worker types and workers. It presents the provisioner/worker
	// type/worker specific actions to the user. When the user triggers an action,
	// the web client takes the registered webhook, substitutes parameters into the
	// URL (see `url`), signs the requests with the Taskcluster credentials of the
	// user operating the web interface, and issues the HTTP request.
	//
	// The level to which the action relates (provisioner, worker type, worker) is
	// called the action context. All actions, regardless of the action contexts,
	// are registered against the provisioner when calling
	// `queue.declareProvisioner`.
	//
	// The action context is used by the web client to determine where in the web
	// interface to present the action to the user as follows:
	//
	// | `context`   | Tool where action is displayed |
	// |-------------|--------------------------------|
	// | provisioner | Provisioner Explorer           |
	// | worker-type | Workers Explorer               |
	// | worker      | Worker Explorer                |
	//
	// See [actions docs](/docs/reference/platform/taskcluster-queue/docs/actions)
	// for more information.
	WorkerTypeAction struct {

		// Only actions with the context `worker-type` are included.
		//
		// Possible values:
		//   * "worker-type"
		Context string `json:"context"`

		// Description of the provisioner.
		Description string `json:"description"`

		// Method to indicate the desired action to be performed for a given resource.
		//
		// Possible values:
		//   * "POST"
		//   * "PUT"
		//   * "DELETE"
		//   * "PATCH"
		Method string `json:"method"`

		// Short names for things like logging/error messages.
		Name string `json:"name"`

		// Appropriate title for any sort of Modal prompt.
		Title json.RawMessage `json:"title"`

		// When an action is triggered, a request is made using the `url` and `method`.
		// Depending on the `context`, the following parameters will be substituted in the url:
		//
		// | `context`   | Path parameters                                          |
		// |-------------|----------------------------------------------------------|
		// | provisioner | <provisionerId>                                          |
		// | worker-type | <provisionerId>, <workerType>                            |
		// | worker      | <provisionerId>, <workerType>, <workerGroup>, <workerId> |
		//
		// _Note: The request needs to be signed with the user's Taskcluster credentials._
		URL string `json:"url"`
	}

	// Request to update a worker-type.
	WorkerTypeRequest struct {

		// Description of the provisioner.
		Description string `json:"description,omitempty"`

		// Date and time after which the worker-type will be automatically
		// deleted by the queue.
		Expires tcclient.Time `json:"expires,omitempty"`

		// This is the stability of the provisioner. Accepted values:
		//   * `experimental`
		//   * `stable`
		//   * `deprecated`
		//
		// Possible values:
		//   * "experimental"
		//   * "stable"
		//   * "deprecated"
		Stability string `json:"stability,omitempty"`
	}

	// Response to a worker-type request from a provisioner.
	WorkerTypeResponse struct {
		Actions []WorkerTypeAction `json:"actions"`

		// Description of the worker-type.
		Description string `json:"description"`

		// Date and time after which the worker-type will be automatically
		// deleted by the queue.
		Expires tcclient.Time `json:"expires"`

		// Date of the last time this worker-type was seen active. `lastDateActive` is updated every 6 hours
		// but may be off by up-to 6 hours. Nonetheless, `lastDateActive` is a good indicator
		// of when the worker-type was last seen active.
		LastDateActive tcclient.Time `json:"lastDateActive"`

		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		ProvisionerID string `json:"provisionerId"`

		// This is the stability of the worker-type. Accepted values:
		//   * `experimental`
		//   * `stable`
		//   * `deprecated`
		//
		// Possible values:
		//   * "experimental"
		//   * "stable"
		//   * "deprecated"
		Stability string `json:"stability"`

		// WorkerType name.
		//
		// Syntax:     ^([a-zA-Z0-9-_]*)$
		// Min length: 1
		// Max length: 38
		WorkerType string `json:"workerType"`
	}
)

// MarshalJSON calls json.RawMessage method of the same name. Required since
// PostArtifactRequest is of type json.RawMessage...
func (this *PostArtifactRequest) MarshalJSON() ([]byte, error) {
	x := json.RawMessage(*this)
	return (&x).MarshalJSON()
}

// UnmarshalJSON is a copy of the json.RawMessage implementation.
func (this *PostArtifactRequest) UnmarshalJSON(data []byte) error {
	if this == nil {
		return errors.New("PostArtifactRequest: UnmarshalJSON on nil pointer")
	}
	*this = append((*this)[0:0], data...)
	return nil
}

// MarshalJSON calls json.RawMessage method of the same name. Required since
// PostArtifactResponse is of type json.RawMessage...
func (this *PostArtifactResponse) MarshalJSON() ([]byte, error) {
	x := json.RawMessage(*this)
	return (&x).MarshalJSON()
}

// UnmarshalJSON is a copy of the json.RawMessage implementation.
func (this *PostArtifactResponse) UnmarshalJSON(data []byte) error {
	if this == nil {
		return errors.New("PostArtifactResponse: UnmarshalJSON on nil pointer")
	}
	*this = append((*this)[0:0], data...)
	return nil
}
